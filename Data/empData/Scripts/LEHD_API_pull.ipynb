{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a1582e-794b-4187-8169-d8fa0376143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dask import dataframe as dd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a211d45f-9954-4ea2-956e-6a8b1d7bc742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import state FIPS codes and abbreviations\n",
    "from datetime import datetime\n",
    "import json\n",
    "import requests\n",
    "\n",
    "path = os.getcwd()\n",
    "index = path.index(\"GrahamKnittel_ECF_PNAS_ReplicationMaterials\")\n",
    "subpath = path[:index + len(\"GrahamKnittel_ECF_PNAS_ReplicationMaterials\")]\n",
    "\n",
    "stateFIPS = pd.read_csv(subpath + \"\\Data\\empData\\Temp\\stateFIPS.csv\",\n",
    "                        dtype={'FIPS': str},\n",
    "                        index_col='Abbr')\n",
    "\n",
    "# Import geographies used by LEHD\n",
    "geographies = pd.read_csv(subpath + \"\\Data\\empData\\Input\\label_geography.csv\",\n",
    "                          dtype={'geography': str})\n",
    "\n",
    "# Import industries used by LEHD\n",
    "industries = pd.read_csv(subpath + \"\\Data\\empData\\Input\\label_industry.csv\",\n",
    "                         dtype={'industry': str, 'ind_level': str})\n",
    "\n",
    "# Load in date coverage information\n",
    "date_coverage = pd.read_csv(subpath + \"\\Data\\empData\\Input\\date_coverage.csv\")\n",
    "date_coverage = pd.merge(date_coverage,\n",
    "                         stateFIPS.loc[:, ['FIPS']],\n",
    "                         how='left',\n",
    "                         left_on='State',\n",
    "                         right_index=True\n",
    "                         )\n",
    "\n",
    "# Set-up\n",
    "# Insert activated key\n",
    "key = '1b5678a1a374e17f9c32c8981fbe81d8f437edc7'\n",
    "\n",
    "# Specify variables for API call\n",
    "endpoints = ['sa?', 'se?', 'rh?']\n",
    "demo = ['sex', 'agegrp', 'race', 'ethnicity', 'education']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51752b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- DEFINE FUNCTION TO PULL LEHD DATA FROM CENSUS API -------------#\n",
    "def getLEHDemp(year, naics_granularity, naics, states='all', endpoint='sa?', demos=demo[:2], write_to_csv=False):\n",
    "    '''\n",
    "    Returns dataframe of county-level LEHD employment data for specified NAICS granularity and subsectors.\n",
    "\n",
    "    Parameters:\n",
    "    ----------------------   \n",
    "    naics_granularity (str) - Single digit number indicating the NAICS code granularity of the employment data desired.\n",
    "    naics (str) - The NAICS subsector to pull employment data for. If len(naics) < naics_granularity, will return employment data for all NAICS subsectors within the specified naics industry with a naics granularity equal to that specifieid by naics_granularity. E.g. if naics_granularity is '3', and naics is '21', then data will be returned for NAICS 211, 212, etc.\n",
    "    states (str or list) - default 'all'. Either 'all' to return nationwide data, or a list of 2-char state abbreviations (characters must be uppercase).\n",
    "    write_to_csv (boolean, defaul False) - Specifies whether to write the results to a csv file. Recommended when pulling a lot of data, to avoid long computation times in future by just reading data from csv file.\n",
    "    '''\n",
    "    \n",
    "    # Check formats of function inputs\n",
    "    if type(year) != str:\n",
    "        raise TypeError('year must be a string.')\n",
    "    if (type(naics_granularity) != str) or len(naics_granularity) > 1:\n",
    "        raise TypeError(\n",
    "            'naics_granularity must be a single-digit number in string format.')\n",
    "    if type(naics) != str or len(naics) > int(naics_granularity):\n",
    "        if naics != '31-33' and naics != '44-45':\n",
    "            raise TypeError(\n",
    "                'naics must be a string of length <= naics_granularity')\n",
    "\n",
    "    # Determine list of industries to consider\n",
    "    ind_df = industries[industries['ind_level'] == naics_granularity].copy()\n",
    "    if naics == '31-33':\n",
    "        ind_df['Keep?'] = ind_df['industry'].apply(\n",
    "            lambda x: True if x[:2] == naics[:2] else\n",
    "            (True if x[:2] == naics[-2:] else\n",
    "             (True if x[:2] == '32' else False))\n",
    "        )\n",
    "    elif naics == '44-45':\n",
    "        ind_df['Keep?'] = ind_df['industry'].apply(\n",
    "            lambda x: True if x[:2] == naics[:2] else\n",
    "            (True if x[:2] == naics[-2:] else False)\n",
    "        )\n",
    "    else:\n",
    "        ind_df['Keep?'] = ind_df['industry'].apply(\n",
    "            lambda x: True if x[:len(naics)] == naics else False\n",
    "        )\n",
    "    ind_df = ind_df[ind_df['Keep?'] == True]\n",
    "\n",
    "    if naics == '00':\n",
    "        industry_list = ['00']\n",
    "    else:\n",
    "        industry_list = list(ind_df['industry'])\n",
    "\n",
    "    # Prepare demographic input\n",
    "    demos_txt = ','.join(demos)\n",
    "    indicators = ['Emp']\n",
    "\n",
    "    # Specify state scope\n",
    "    if states == 'all':\n",
    "        geo = list(stateFIPS['FIPS'])\n",
    "    else:\n",
    "        geo = list(stateFIPS.loc[states, 'FIPS'])\n",
    "\n",
    "    # Set up dictionary to store pulled data\n",
    "    dfs_ovr = {}     # To store dataframes on employment across all demographics at the county-level, for each state\n",
    "\n",
    "    # Iterative through each state\n",
    "    for state in geo:\n",
    "\n",
    "        # To store dataframes of employment data for each industry within a given state.\n",
    "        df_list = []\n",
    "\n",
    "        for industry in industry_list:\n",
    "            emp_year = year\n",
    "\n",
    "            # Check whether date has data for selected year\n",
    "            if int(date_coverage[date_coverage['FIPS'] == state].reset_index(drop=True).loc[0, 'End Quarter'][:4]) < int(emp_year):\n",
    "                emp_year = date_coverage[date_coverage['FIPS'] == state].reset_index(\n",
    "                    drop=True).loc[0, 'End Quarter'][:4]\n",
    "\n",
    "            # Make an API call and store the response.\n",
    "            url = f'https://api.census.gov/data/timeseries/qwi/{endpoint}get={indicators[0]},{demos_txt}\\\n",
    "&for=county:*&in=state:{state}&year={emp_year}&quarter=1&quarter=2&quarter=3&quarter=4&\\\n",
    "industry={industry}&key={key}'\n",
    "\n",
    "            data = requests.get(url)\n",
    "\n",
    "            # Check that all calls return data\n",
    "            if data.status_code == 400:\n",
    "                raise ValueError(\n",
    "                    f'More than 400,000 cells returned at {url}. Specify an alternate query that lessens output.')\n",
    "\n",
    "            # Store the API response in a variable.\n",
    "            try:\n",
    "                available_data = data.json()\n",
    "\n",
    "                df = pd.DataFrame(\n",
    "                    available_data[1:], columns=available_data[0])\n",
    "                df['Emp'] = pd.to_numeric(df['Emp'])\n",
    "\n",
    "                # Annualize data by taking mean across quarters\n",
    "                df = df.groupby(by=['state', 'county', 'year', 'industry',\n",
    "                                f'{demos[0]}', f'{demos[1]}'], as_index=False).mean()\n",
    "\n",
    "                # Only keep overall data\n",
    "                df = df[(df[f'{demos[0]}'] == '0') & (\n",
    "                    df[f'{demos[1]}'] == 'A00')].reset_index(drop=True)\n",
    "\n",
    "                # Append to the list of dataframes for each industry\n",
    "                df_list.append(df)\n",
    "\n",
    "            # If there is 0 employment for this industry in a certain state, ValueError will be raised. Pass this.\n",
    "            except ValueError:\n",
    "                print(\n",
    "                    f'0 employment for NAICS {industry} in state {state}, therefore passed')\n",
    "                pass\n",
    "\n",
    "        # Store results by concatenating df_list into a single dataframe for the overall case as well as the demographic case\n",
    "        try:\n",
    "            # Store final dataframes in dictionary keyed by state\n",
    "            dfs_ovr[state] = pd.concat(df_list)\n",
    "\n",
    "        # If there is no employment in any of the assessed industries in this state, valueerror will be raised. Pass this.\n",
    "        except ValueError:\n",
    "            print(f'No employees in NAICS {naics} in state {state}. Pass.')\n",
    "            pass\n",
    "\n",
    "    # Concatenate dataframes for each state into one big dataframe. Add county FIPS column.\n",
    "    emp_ovr = pd.concat(dfs_ovr.values()).reset_index(drop=True)\n",
    "    emp_ovr['FIPS'] = emp_ovr['state'] + emp_ovr['county']\n",
    "\n",
    "    # Drop any duplicate columns\n",
    "    emp_ovr = emp_ovr.drop_duplicates(ignore_index=True)\n",
    "\n",
    "    if write_to_csv == True:\n",
    "        emp_ovr.to_csv(subpath + f'/Data/empData/Temp/emp_ovr_{naics}_{naics_granularity}dig_{year}.csv')\n",
    "\n",
    "    return emp_ovr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "b62c26efd9b7dc933240e6c8be0310d5618371abe44d01463caf7f4af3a99891"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
