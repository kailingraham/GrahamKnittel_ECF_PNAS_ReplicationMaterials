{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7639bf83-41ae-4466-a55e-891761082411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23e8b69-2a75-485c-be96-d35ad722bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in a GeoJSON file containing the geometry information for US counties, where feature.id is a FIPS code. \n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:\n",
    "    counties = json.load(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8dfe271d-e79b-48e6-a9b0-f60f830674db",
   "metadata": {},
   "source": [
    "# Notebook Outline\n",
    "This notebook uses the annual aggregate dataset from the Comstock commercial building energy consumption 'End-Use Load Profiles' (https://www.nrel.gov/buildings/end-use-load-profiles.html) to calculate the emissions intensity in absolute terms, per capita, and per employee for a subset of commercial industry sectors. The steps involved are as follows:\n",
    "1. Prepare comstock and employment datasets\n",
    "2. Calculate emissions\n",
    "3. Compute emissions per capita and emissions per employee\n",
    "\n",
    "Note that all energy consumption fields are specified in kWh."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c3fe7e5-0baa-4b0a-a38f-b4b7d9d2c749",
   "metadata": {},
   "source": [
    "# 1 Prepare datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ded9a2e-2402-4d25-94bc-ef3ab5e54846",
   "metadata": {},
   "source": [
    "## 1.1 Prepare Comstock data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ca77293-4b3b-45e3-a56b-0ab678fc6bca",
   "metadata": {},
   "source": [
    "NREL uses Comstock to publish 'End-Use Load Profiles for the U.S. Building Stock' (https://www.nrel.gov/buildings/end-use-load-profiles.html). These are timeseries load profiles for all building types, derived using the Comstock and Restock models. To get these timeseries profiles, total estimates of fuel usage of different commercial buildings in different counties is derived and fed into the timeseries models. These estimates are what we need for our analysis, and are available in the 'metadata' file in the Comstock data lake (overall data lake here: https://data.openei.org/submissions/4520. Readme for comstock datafiles here, including changelog: https://oedi-data-lake.s3.amazonaws.com/nrel-pds-building-stock/end-use-load-profiles-for-us-building-stock/README.md. Metadata file here: https://data.openei.org/s3_viewer?bucket=oedi-data-lake&prefix=nrel-pds-building-stock%2Fend-use-load-profiles-for-us-building-stock%2F2021%2Fcomstock_amy2018_release_1%2Fmetadata%2F). Comstock data is for 2018. Note that in 2022 a series of revisions and updates were made to the Comstock metadata files - should be sure to use most up-to-date files. See Readme for changes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fcd14ab0-ed40-4274-a974-4a3e04cb4b7e",
   "metadata": {},
   "source": [
    "### 1.1.1. Read in and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2cb0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import annual energy usage data ('metadata')\n",
    "metadata = pq.read_table('../Input/metadata.parquet').to_pandas()\n",
    "\n",
    "# Read in data dictionary\n",
    "data_dictionary = pd.read_csv('../Input/data_dictionary.tsv', delimiter='\\t')\n",
    "\n",
    "# Isolate revelant data from metadata for a) emissions calculations, and b) occupancy regression\n",
    "# A)\n",
    "all_cols = metadata.columns\n",
    "qual_cols = ['in.county', 'in.state_abbreviation',\n",
    "             'in.building_type', 'in.building_subtype', 'in.sqft']\n",
    "emissions_calcs_cols = ['in.hvac_system_type', 'in.heating_fuel', 'in.service_water_heating_fuel',\n",
    "                        'out.electricity.heating.energy_consumption', 'out.electricity.water_systems.energy_consumption',\n",
    "                        'out.electricity.total.energy_consumption', 'out.natural_gas.heating.energy_consumption',\n",
    "                        'out.natural_gas.interior_equipment.energy_consumption',\n",
    "                        'out.natural_gas.water_systems.energy_consumption', 'out.other_fuel.heating.energy_consumption',\n",
    "                        'out.other_fuel.water_systems.energy_consumption', 'out.district_cooling.total.energy_consumption',\n",
    "                        'out.district_heating.total.energy_consumption', 'out.natural_gas.total.energy_consumption',\n",
    "                        'out.other_fuel.total.energy_consumption', 'weight']\n",
    "\n",
    "comstock_raw = metadata[qual_cols + emissions_calcs_cols]\n",
    "\n",
    "# Read in and merge county names onto datapoints\n",
    "#  Add county and state FIPS fields from in.county field\n",
    "comstock_raw['FIPS'] = comstock_raw['in.county'].apply(lambda x: x[1:3] + x[4:-1])\n",
    "comstock_raw['STATEFIPS'] = comstock_raw['FIPS'].apply(lambda x: x[:2])\n",
    "\n",
    "#  Read in county fips labels [NOTE: this file has been edited from that used in other code to ensure county names and their formatting match]\n",
    "fips = pd.read_excel('../Temp/fips_edited.xlsx',\n",
    "                     usecols=[1, 2, 3, 4],\n",
    "                     header=None,\n",
    "                     names=['FIPS', 'County', 'State Name', 'State'],\n",
    "                     dtype={'FIPS': str}\n",
    "                     )\n",
    "fips['County'] = fips['County'].str.lower()\n",
    "\n",
    "#  Merge county names onto FIPS\n",
    "comstock_raw = pd.merge(comstock_raw, fips[['FIPS', 'County']], how='left', on='FIPS')\n",
    "\n",
    "#  Drop and rename fields\n",
    "comstock_raw = comstock_raw.drop(columns=['in.county']).rename(\n",
    "    columns={'in.state_abbreviation': 'State'})\n",
    "\n",
    "# Replace FIPS 02270 Wade hampton (AK) with 02158 Kusilvak, and 46113 Shannon with 46102 Oglala lakota, according to July 2015 changes\n",
    "for i in np.arange(len(comstock_raw)):\n",
    "    if comstock_raw.loc[i, 'FIPS'] == '02270':\n",
    "        comstock_raw.loc[i, 'FIPS'] = '02158'\n",
    "        comstock_raw.loc[i, 'County'] = 'kusilvak'\n",
    "        comstock_raw.loc[i, 'State'] = 'AK'\n",
    "    elif comstock_raw.loc[i, 'FIPS'] == '46113':\n",
    "        comstock_raw.loc[i, 'FIPS'] = '46102'\n",
    "        comstock_raw.loc[i, 'County'] = 'oglala lakota'\n",
    "        comstock_raw.loc[i, 'State'] = 'SD'\n",
    "\n",
    "#  Check that all county names were correctly merge\n",
    "if len(comstock_raw[comstock_raw['County'].isna()]) == 0:\n",
    "    print('Successful merge. Continue.')\n",
    "else:\n",
    "    print('Error in merge. FIPS affected:',\n",
    "          comstock_raw[comstock_raw['County'].isna()]['FIPS'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c3c581a-8919-470f-8d5d-862dea8ca3e7",
   "metadata": {},
   "source": [
    "### 1.1.2 Determine NAICS-building type crosswalk to use when attributing employment data to emissions data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f05d029-6df0-4b02-9761-e8d2f4f86903",
   "metadata": {},
   "source": [
    "Comstock indicates industry through building type rather than industry classification (e.g. NAICS), however employment data is given per NAICS industry. Therefore, manually constructed 8 commercial categories that span the building types included in comstock, and determined the corresponding NAICS codes that fit into each of these categories. Note that while some categories map directly to NAICS codes (e.g. hospital), others (e.g. office) are simply building type categories. This is because these building types can't be feasibly mapped to any specific industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3f6595-2a8f-4b7f-956b-bf74a9281a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in industry classifications and their mapping to comstock's building types\n",
    "comstock_ind_crosswalk = pd.read_excel(\n",
    "    '../Temp/comstock_ind_crosswalk.xlsx', dtype={'ind_code': str})\n",
    "# Merge these categories    onto comstock dataframe\n",
    "comstock = pd.merge(comstock_raw, comstock_ind_crosswalk, how='left', on='in.building_type')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e78c8c8-77c2-403b-b4fd-45495977d402",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2 Calculate commercial emissions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ec30693-d49d-442d-9403-1792fefd92bc",
   "metadata": {},
   "source": [
    "Comstock gives energy consumption in kWh. Use the following emissions factors to determine the associated CO2e emissions for each fuel type:\n",
    "- Natural gas: 116.65 lbCO2e per MMBtu (https://www.eia.gov/environment/emissions/co2_vol_mass.php)\n",
    "- Electricity: Use eGRID 2016 electricity carbon intensity at the eGRID subregion level (see '~/industrial/Scripts/2023-06-27_countyElecIntensity.ipynb')\n",
    "- District heating: Assume heating comes from gas-fired CHP, therefore use natural gas emissions factor.\n",
    "- District cooling: Assume district cooling system uses an electric chiller, therefore use electricity emissions factor.\n",
    "- Other fuel: Assume to be distillate fuel oil (aka heating fuel), 163.45 lbCO2e per MMBtu (https://www.eia.gov/environment/emissions/co2_vol_mass.php)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87b70568-2a00-48b3-a453-67b650477341",
   "metadata": {},
   "source": [
    "## 2.1 From electricity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53ae1fc8-0bcb-49ec-870c-06ad9b84c2fb",
   "metadata": {},
   "source": [
    "### 2.1.1 Specify emissions factors based on eGRID subregions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04de8f25-969a-4972-9181-fcacb17d8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in electricity carbon intensity and merge onto manufacturing energy consumption data\n",
    "counties_elec_intensity = pd.read_csv(\n",
    "    '../../industrial/Temp/counties_elec_intensity.csv',\n",
    "    dtype={'id': str, 'STATE': str, 'COUNTY': str}\n",
    ").drop(columns='Unnamed: 0')\n",
    "counties_elec_intensity['SRC2ERTA'] = counties_elec_intensity['SRC2ERTA'] / 1000\n",
    "counties_elec_intensity = counties_elec_intensity.rename(\n",
    "    columns={'id': 'FIPS', 'SRC2ERTA': 'lbCO2e_perkWh_elec'})\n",
    "\n",
    "# Merge electricity carbon intensity onto comstock data by FIPS code\n",
    "comstock = comstock.merge(\n",
    "    counties_elec_intensity[['FIPS', 'SUBRGN', 'lbCO2e_perkWh_elec']],\n",
    "    how='left',\n",
    "    on='FIPS'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f605329-3bc6-4c59-a81a-55ead4685e0d",
   "metadata": {},
   "source": [
    "### 2.1.2 Perform calculation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3ca713f-cfed-4920-b89f-3af1838d3e05",
   "metadata": {},
   "source": [
    "Should calculate electricity consumption for heating, for water heating, and in total (which includes heating + water heating + general electricity consumption)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a011ecfe-ff99-4956-a029-089d47450e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive general electricity consumption (i.e. that not used for heating or water systems)\n",
    "comstock['derived.electricity.general.energy_consumption'] = comstock['out.electricity.total.energy_consumption'] - \\\n",
    "    comstock['out.electricity.heating.energy_consumption'] - \\\n",
    "    comstock['out.electricity.water_systems.energy_consumption']\n",
    "\n",
    "# For each electricity consumption column, calculate the CO2e emissions associated.\n",
    "comstock['lbCO2e_elec_heat'] = comstock['out.electricity.heating.energy_consumption'] * \\\n",
    "    comstock['lbCO2e_perkWh_elec']\n",
    "comstock['lbCO2e_elec_water'] = comstock['out.electricity.water_systems.energy_consumption'] * \\\n",
    "    comstock['lbCO2e_perkWh_elec']\n",
    "comstock['lbCO2e_elec_general'] = comstock['derived.electricity.general.energy_consumption'] * \\\n",
    "    comstock['lbCO2e_perkWh_elec']\n",
    "comstock['lbCO2e_elec_total'] = comstock['out.electricity.total.energy_consumption'] * \\\n",
    "    comstock['lbCO2e_perkWh_elec']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3dbd717-8974-4154-9425-f22e6fd02c75",
   "metadata": {},
   "source": [
    "## 2.2 From natural gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3152f8d2-744c-4a96-af9d-9f44838601b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural gas emissions factor\n",
    "ef_ng = 116.65 / 293.07107  # lbCO2e/MMBTU / kWh/MMBtu\n",
    "\n",
    "# Calculate emissions for each natural gas consumption column\n",
    "comstock['lbCO2e_ng_heat'] = comstock['out.natural_gas.heating.energy_consumption'] * ef_ng\n",
    "comstock['lbCO2e_ng_water'] = comstock['out.natural_gas.water_systems.energy_consumption'] * ef_ng\n",
    "comstock['lbCO2e_ng_intequip'] = comstock['out.natural_gas.interior_equipment.energy_consumption'] * ef_ng\n",
    "comstock['lbCO2e_ng_total'] = comstock['out.natural_gas.total.energy_consumption'] * ef_ng"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4cff54b3-feb5-45e8-83e8-2436cba0b879",
   "metadata": {},
   "source": [
    "## 2.3 District heating/cooling and other fuels\n",
    "Emissions for NG water heating taken from https://www.researchgate.net/publication/291951427_Greenhouse_gas_emissions_from_domestic_hot_water_Heat_pumps_compared_to_most_commonly_used_systems.\n",
    "Used base case for a storage gas heater (98% of U.S. water heating had storage tanks in 2009)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f84fcb2-a268-40cd-95ba-249f4b84ceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "comstock['lbCO2e_dist_heat'] = comstock['out.district_heating.total.energy_consumption'] * ef_ng\n",
    "comstock['lbCO2e_dist_cool'] = comstock['out.district_cooling.total.energy_consumption'] * \\\n",
    "    comstock['lbCO2e_perkWh_elec']\n",
    "\n",
    "comstock['lbCO2e_other_heat'] = comstock['out.other_fuel.heating.energy_consumption'] * \\\n",
    "    163.45 / 293.07107  # lbCO2e/MMBTU / kWh/MMBtu\n",
    "comstock['lbCO2e_other_water'] = comstock['out.other_fuel.water_systems.energy_consumption'] * \\\n",
    "    163.45 / 293.07107  # lbCO2e/MMBTU / kWh/MMBtu\n",
    "comstock['lbCO2e_other_total'] = comstock['out.other_fuel.total.energy_consumption'] * \\\n",
    "    163.45 / 293.07107  # lbCO2e/MMBTU / kWh/MMBtu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f1e9ed6-6a41-4476-b288-cd6052a6a9a2",
   "metadata": {},
   "source": [
    "## 2.4 Compute weighted emissions and totals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "089ac6f6-41e8-4143-bab3-b4d86b74f38b",
   "metadata": {},
   "source": [
    "Each building in the dataset has a weight, which is meant to represent the number of 'identical' buildings in that county. Therefore, all emissions figures should be multiplied by the weight to obtain a representative value of the total emissions for a given building type in a given county.<br>\n",
    "Additionally, it might be interesting to understand the extent to which emissions can be attributed to heating, general electricity consumption, water heating etc (i.e. by energy use), as well as the extent to which the emissions are from natural gas vs electricity vs fuel oil etc. consumption (i.e. by fuel type). Should compute these totals here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad022930-4bf6-468c-8141-c2e9576eb018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each lbCO2e column, calculate a corresponding weighted emissions column, denoted by '_w'\n",
    "weighted_col_names = []\n",
    "i = 0\n",
    "\n",
    "for col in list(comstock.columns)[-13:]:\n",
    "    weighted_col_names.append(col + '_w')\n",
    "    comstock[weighted_col_names[i]] = comstock[col] * comstock['weight']\n",
    "    i += 1\n",
    "\n",
    "# Already have by fuel type, but should now compute total by end use\n",
    "comstock['lbCO2e_heat_total_w'] = comstock['lbCO2e_elec_heat_w'] + \\\n",
    "    comstock['lbCO2e_ng_heat_w'] + comstock['lbCO2e_dist_heat_w'] + comstock['lbCO2e_other_heat_w']\n",
    "comstock['lbCO2e_water_total_w'] = comstock['lbCO2e_elec_water_w'] + \\\n",
    "    comstock['lbCO2e_ng_water_w'] + comstock['lbCO2e_other_water_w']\n",
    "\n",
    "# Finally, compute total co2e per building type per county\n",
    "comstock['lbCO2e_total_w'] = comstock['lbCO2e_elec_total_w'] + comstock['lbCO2e_ng_total_w'] + comstock['lbCO2e_dist_heat_w'] + \\\n",
    "    comstock['lbCO2e_dist_cool_w'] + comstock['lbCO2e_other_total_w']\n",
    "comstock['tonCO2e_total_w'] = comstock['lbCO2e_total_w'] / 2000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cbc29342-597f-4cc7-92c8-d89fe688cc45",
   "metadata": {},
   "source": [
    "## 2.5 Perform different groupings of comstock data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "022b8eea-c8dc-4aa9-8cd5-9fbf20f72cf9",
   "metadata": {},
   "source": [
    "As in the industrial analyses, should try and group data at different granularities so that different analyses are possible. Building subtype, HVAC system type and sqaure footage should be aggregated up in all cases, as this info is too granular, and all geographic granularity should be kept at the county level. Should create a dictionary with the following dataframes:\n",
    "1. Full energy usage data for each comstock building type, heating fuel, water heating fuel etc.\n",
    "2. Grouped energy usage data per comstock building type, aggregating usage/emissions across different heating fuels etc.\n",
    "3. Energy usage data using employment building categories (i.e. 'ind_name' and 'ind_code').\n",
    "4. Energy usage data for the entire commercial sector (i.e. no building-type specification, just aggregate at county level)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40b3551c-37a6-42bb-ae02-767ef2ddb15e",
   "metadata": {},
   "source": [
    "### 2.5.1 Construct dataframe 1 (full data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cbde64-6f50-4e5a-b4b1-79642506a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by all categorical fields except building subtype, square footage and hvac system type\n",
    "comstock_grouped = comstock.groupby(by=['State', 'in.building_type', 'in.heating_fuel',\n",
    "                                        'in.service_water_heating_fuel', 'FIPS',\n",
    "                                        'STATEFIPS', 'County', 'ind_name', 'ind_code',\n",
    "                                        'SUBRGN', 'lbCO2e_perkWh_elec'],\n",
    "                                    as_index=False).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e34320e7-f9c3-4849-a8e0-830a3bdb3012",
   "metadata": {},
   "source": [
    "### 2.5.2 Construct dataframe 2 (per building type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5de883-1d15-4137-b76e-ecdf1776537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group dataframe 1 by building type\n",
    "comstock_buildtype = comstock_grouped.groupby(\n",
    "    by=['State', 'in.building_type', 'FIPS', 'STATEFIPS', 'County',\n",
    "        'ind_name', 'ind_code', 'SUBRGN', 'lbCO2e_perkWh_elec'],\n",
    "    as_index=False\n",
    ").sum()\n",
    "# comstock_buildtype.to_csv('../Temp/comstock_buildtype.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa6d6b9e-8781-49ba-a185-8a4a4f51a5c9",
   "metadata": {},
   "source": [
    "### 2.5.3 Construct dataframe 3 (per employment building category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dbcf5e-e83a-42bf-b661-718ba47609d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group dataframe 1 by 'ind_name' and 'ind_code'\n",
    "comstock_indtype = comstock_grouped.groupby(\n",
    "    by=['State', 'FIPS', 'STATEFIPS', 'County', 'ind_name',\n",
    "        'ind_code', 'SUBRGN', 'lbCO2e_perkWh_elec'],\n",
    "    as_index=False\n",
    ").sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7007bb6c-aa22-4e54-970e-88dbc33fff06",
   "metadata": {},
   "source": [
    "### 2.5.4 Construct dataframe 4 (total per county)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdae7f27-aa1b-4f85-8067-f6b2152e00b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group dataframe 1 by county\n",
    "comstock_all = comstock_grouped.groupby(\n",
    "    by=['State', 'FIPS', 'STATEFIPS', 'County',\n",
    "        'SUBRGN', 'lbCO2e_perkWh_elec'],\n",
    "    as_index=False\n",
    ").sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cb75dd0-cc0a-46f8-a3b2-fe50d0565f6d",
   "metadata": {},
   "source": [
    "### 2.5.5 Hold all dataframes in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf360a2-4543-4094-a037-fb4b0ddfbd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_dfs = {'full': comstock_grouped,\n",
    "            'buildtype': comstock_buildtype,\n",
    "            'indtype': comstock_indtype,\n",
    "            'total': comstock_all}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe99e72e-fa14-4939-8e68-87224a44fdf3",
   "metadata": {},
   "source": [
    "# 3 Compute emissions per capita and emissions per employee"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c878d1b6-298a-4a68-8cba-8bb1b5798516",
   "metadata": {},
   "source": [
    "## 3.1 Per capita"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5b22ef4-d58b-4ebb-8114-08d4bcc9715e",
   "metadata": {},
   "source": [
    "For non-census years, the U.S. Census Bureau's Population Estimates Program uses a cohort-component method to estimate the change in county-level population by tallying recorded births, deaths and migrations since the last population estimate and using them to derive a new county-level estimate. More details here https://www.census.gov/data/datasets/time-series/demo/popest/2010s-counties-total.html, documentation here: https://www2.census.gov/programs-surveys/popest/technical-documentation/methodology/2010-2019/natstcopr-methv2.pdf.<br>\n",
    "This data can be accessed via the Census Data API. An API pull script has been constructed in another notebook ('CensusBureauPopEstimates.ipynb'), and will be called here to extract the population data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec74fbd-6ccb-4475-9f7b-0f763c5480ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CensusBureauPopEstimates.ipynb to define function get_pop_estimate() needed to extract Census Population Estimates for a given year data\n",
    "%run ../../empData/Scripts/CensusBureauPopEstimates.ipynb\n",
    "\n",
    "# Use get_pop_estimate() function to extract 2016 population estimates for each county\n",
    "county_pop_2018 = get_pop_estimate(2018, 'county')\n",
    "county_pop_2018['FIPS'] = county_pop_2018['state'] + county_pop_2018['county']\n",
    "\n",
    "# Merge population data onto all comm_dfs, and compute total emissions per capita\n",
    "comm_dfs_pop = comm_dfs.copy()\n",
    "\n",
    "for df in comm_dfs_pop.keys():\n",
    "\n",
    "    # Merge population data onto dataframe\n",
    "    comm_dfs_pop[df] = pd.merge(comm_dfs_pop[df], county_pop_2018[[\n",
    "                                'FIPS', 'POP']], how='left', on='FIPS')\n",
    "\n",
    "    # Compute total emissions per capita, and log10 for visualization purposes\n",
    "    comm_dfs_pop[df]['lbCO2e_percapita_w'] = comm_dfs_pop[df]['lbCO2e_total_w'] / \\\n",
    "        comm_dfs_pop[df]['POP']\n",
    "    comm_dfs_pop[df]['lbCO2e_percapita_w_log10'] = np.log10(comm_dfs_pop[df]['lbCO2e_percapita_w'])\n",
    "\n",
    "    comm_dfs_pop[df]['tonCO2e_percapita_w'] = comm_dfs_pop[df]['tonCO2e_total_w'] / \\\n",
    "        comm_dfs_pop[df]['POP']\n",
    "    comm_dfs_pop[df]['tonCO2e_percapita_w_log10'] = np.log10(\n",
    "        comm_dfs_pop[df]['tonCO2e_percapita_w'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8842a08-6299-4903-ad92-073eaf747544",
   "metadata": {},
   "source": [
    "## 3.2 Per employee"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da1c764c-c9fb-4df3-8ed9-d3f3ce724763",
   "metadata": {},
   "source": [
    "### 3.2.1 Read in LEHD data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93c4e841-9681-4de0-82cb-ff5d9d26cd97",
   "metadata": {},
   "source": [
    "Using the LEHD API pull script we can pull LEHD employment data for each of the NAICS codes we consider in our analysis. The mapping of building types to NAICS codes used for this analysis is below. Any other NAICS codes are not considered in this analysis.\n",
    "- <b>Office</b>: NAICS 51-55, 92, 561, 425\n",
    "- <b>Retail</b>: NAICS 44-45\n",
    "- <b>Warehousing & storage</b>: NAICS 493, 423, 424\n",
    "- <b>Restaurants</b>: NAICS 722\n",
    "- <b>Accommodation</b>: NAICS 721\n",
    "- <b>Schools</b>: NAICS 6111\n",
    "- <b>Hospitals</b>: NAICS 622\n",
    "- <b>Oupatient</b>: NAICS 621"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8c47e1-ba63-45ec-920f-fbb65e7b6977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run LEHD API pull script to call function that pulls LEHD employment data\n",
    "# %run ../../empData/Scripts/LEHD_API_pull.ipynb\n",
    "\n",
    "# Run API pulls, or read from CSV\n",
    "#  Hospitals and outpatient\n",
    "# lehd_hosp = getLEHDemp('2018','3', '622', write_to_csv = True)\n",
    "# lehd_outp = getLEHDemp('2018','3', '621', write_to_csv = True)\n",
    "\n",
    "lehd_hosp = pd.read_csv('../../empData/Temp/emp_ovr_622_3dig_2018.csv', dtype={\n",
    "                        'state': str, 'county': str, 'FIPS': str, 'sex': str, 'year': str, 'industry': str}).drop(columns=['Unnamed: 0'])\n",
    "lehd_outp = pd.read_csv('../../empData/Temp/emp_ovr_621_3dig_2018.csv', dtype={\n",
    "                        'state': str, 'county': str, 'FIPS': str, 'sex': str, 'year': str, 'industry': str}).drop(columns=['Unnamed: 0'])\n",
    "\n",
    "#  Schools\n",
    "# lehd_school = getLEHDemp('2018','4', '6111', write_to_csv = True)\n",
    "lehd_school = pd.read_csv('../../empData/Temp/emp_ovr_6111_4dig_2018.csv', dtype={\n",
    "                          'state': str, 'county': str, 'FIPS': str, 'sex': str, 'year': str, 'industry': str}).drop(columns=['Unnamed: 0'])\n",
    "\n",
    "#  Accommodation\n",
    "# lehd_accom = getLEHDemp('2018', '3', '721', write_to_csv = True)\n",
    "lehd_accom = pd.read_csv('../../empData/Temp/emp_ovr_721_3dig_2018.csv', dtype={\n",
    "                         'state': str, 'county': str, 'FIPS': str, 'sex': str, 'year': str, 'industry': str}).drop(columns=['Unnamed: 0'])\n",
    "\n",
    "#  Restaurants\n",
    "# lehd_rest = getLEHDemp('2018', '3', '722', write_to_csv = True)\n",
    "\n",
    "lehd_rest = pd.read_csv('../../empData/Temp/emp_ovr_722_3dig_2018.csv', dtype={\n",
    "                        'state': str, 'county': str, 'FIPS': str, 'sex': str, 'year': str, 'industry': str}).drop(columns=['Unnamed: 0'])\n",
    "\n",
    "#  Warehousing & storage\n",
    "# lehd_ware1 = getLEHDemp('2018', '3', '493', write_to_csv = True)\n",
    "# lehd_ware2 = getLEHDemp('2018', '3', '423', write_to_csv = True)\n",
    "# lehd_ware3 = getLEHDemp('2018', '3', '424', write_to_csv = True)\n",
    "\n",
    "lehd_ware1 = pd.read_csv(\n",
    "    '../../empData/Temp/emp_ovr_493_3dig_2018.csv',\n",
    "    dtype={'state': str, 'county': str, 'FIPS': str, 'sex': str, 'year': str, 'industry': str}\n",
    ").drop(columns=['Unnamed: 0'])\n",
    "lehd_ware2 = pd.read_csv(\n",
    "    '../../empData/Temp/emp_ovr_423_3dig_2018.csv',\n",
    "    dtype={'state': str, 'county': str, 'FIPS': str, 'sex': str, 'year': str, 'industry': str}\n",
    ").drop(columns=['Unnamed: 0'])\n",
    "lehd_ware3 = pd.read_csv(\n",
    "    '../../empData/Temp/emp_ovr_424_3dig_2018.csv',\n",
    "    dtype={'state': str, 'county': str, 'FIPS': str, 'sex': str, 'year': str, 'industry': str}\n",
    ").drop(columns=['Unnamed: 0'])\n",
    "\n",
    "lehd_ware = pd.concat([lehd_ware1, lehd_ware2, lehd_ware3], ignore_index=True)\n",
    "\n",
    "#  Retail\n",
    "# lehd_retail = getLEHDemp('2018', '2', '44', write_to_csv = True)\n",
    "\n",
    "lehd_retail = pd.read_csv(\n",
    "    '../../empData/Temp/emp_ovr_44_2dig_2018.csv',\n",
    "    dtype={'state': str, 'county': str, 'FIPS': str, 'sex': str, 'year': str, 'industry': str}\n",
    ").drop(columns=['Unnamed: 0'])\n",
    "\n",
    "#  Office\n",
    "# lehd_off1 = getLEHDemp('2018', '2', '51', write_to_csv = True)\n",
    "# lehd_off2 = getLEHDemp('2018', '2', '52', write_to_csv = True)\n",
    "# lehd_off3 = getLEHDemp('2018', '2', '53', write_to_csv = True)\n",
    "# lehd_off4 = getLEHDemp('2018', '2', '54', write_to_csv = True)\n",
    "# lehd_off5 = getLEHDemp('2018', '2', '55', write_to_csv = True)\n",
    "# lehd_off6 = getLEHDemp('2018', '2', '92', write_to_csv = True)\n",
    "# lehd_off7 = getLEHDemp('2018', '3', '561', write_to_csv = True)\n",
    "# lehd_off8 = getLEHDemp('2018', '3', '425', write_to_csv = True)\n",
    "\n",
    "lehd_off1 = pd.read_csv(\n",
    "    '../../empData/Temp/emp_ovr_51_2dig_2018.csv',\n",
    "    dtype={'state': str, 'county': str, 'FIPS': str, 'sex': str, 'year': str, 'industry': str}\n",
    ").drop(columns=['Unnamed: 0'])\n",
    "lehd_off2 = pd.read_csv(\n",
    "    '../../empData/Temp/emp_ovr_52_2dig_2018.csv',\n",
    "    dtype={'state': str, 'county': str, 'FIPS': str, 'sex': str, 'year': str, 'industry': str}\n",
    ").drop(columns=['Unnamed: 0'])\n",
    "lehd_off3 = pd.read_csv(\n",
    "    '../../empData/Temp/emp_ovr_53_2dig_2018.csv',\n",
    "    dtype={'state': str, 'county': str, 'FIPS': str, 'sex': str, 'year': str, 'industry': str}\n",
    ").drop(columns=['Unnamed: 0'])\n",
    "lehd_off4 = pd.read_csv(\n",
    "    '../../empData/Temp/emp_ovr_54_2dig_2018.csv',\n",
    "    dtype={'state': str, 'county': str, 'FIPS': str, 'sex': str, 'year': str, 'industry': str}\n",
    ").drop(columns=['Unnamed: 0'])\n",
    "lehd_off5 = pd.read_csv(\n",
    "    '../../empData/Temp/emp_ovr_55_2dig_2018.csv',\n",
    "    dtype={'state': str, 'county': str, 'FIPS': str, 'sex': str, 'year': str, 'industry': str}\n",
    ").drop(columns=['Unnamed: 0'])\n",
    "lehd_off6 = pd.read_csv(\n",
    "    '../../empData/Temp/emp_ovr_92_2dig_2018.csv',\n",
    "    dtype={'state': str, 'county': str, 'FIPS': str, 'sex': str, 'year': str, 'industry': str}\n",
    ").drop(columns=['Unnamed: 0'])\n",
    "lehd_off7 = pd.read_csv(\n",
    "    '../../empData/Temp/emp_ovr_561_3dig_2018.csv',\n",
    "    dtype={'state': str, 'county': str, 'FIPS': str, 'sex': str, 'year': str, 'industry': str}\n",
    ").drop(columns=['Unnamed: 0'])\n",
    "lehd_off8 = pd.read_csv(\n",
    "    '../../empData/Temp/emp_ovr_425_3dig_2018.csv',\n",
    "    dtype={'state': str, 'county': str, 'FIPS': str, 'sex': str, 'year': str, 'industry': str}\n",
    ").drop(columns=['Unnamed: 0'])\n",
    "\n",
    "lehd_off = pd.concat([lehd_off1, lehd_off2, lehd_off3, lehd_off4, lehd_off5,\n",
    "                     lehd_off6, lehd_off7, lehd_off8], ignore_index=True)\n",
    "lehd_off_excl_wholesale = pd.concat(\n",
    "    [lehd_off1, lehd_off2, lehd_off3, lehd_off4, lehd_off5, lehd_off6, lehd_off7],\n",
    "    ignore_index=True)\n",
    "\n",
    "# Note that, if not disaggregating into subsectors, can just use 42 instead of separately pulling 424, 423 and 422.\n",
    "# lehd_wholesale = getLEHDemp('2018', '2', '42', write_to_csv = True)\n",
    "lehd_wholesale = pd.read_csv(\n",
    "    '../../empData/Temp/emp_ovr_42_2dig_2018.csv',\n",
    "    dtype={'state': str, 'county': str, 'FIPS': str, 'sex': str, 'year': str, 'industry': str}\n",
    ").drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Same is true for accommodation and restaurants\n",
    "# lehd_accom_food = getLEHDemp('2018', '2', '72', write_to_csv = True)\n",
    "lehd_accom_food = pd.read_csv(\n",
    "    '../../empData/Temp/emp_ovr_72_2dig_2018.csv',\n",
    "    dtype={'state': str, 'county': str, 'FIPS': str, 'sex': str, 'year': str, 'industry': str}\n",
    ").drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc23fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dataframe of NAICS-level employment to csv for decomposition analysis\n",
    "lehd_naics = pd.concat([lehd_off1, lehd_off2, lehd_off3, lehd_off4,\n",
    "                        lehd_off5, lehd_off6, lehd_off7, lehd_off8,\n",
    "                        lehd_hosp, lehd_outp, lehd_school, lehd_accom,\n",
    "                        lehd_rest, lehd_ware, lehd_retail],\n",
    "                       ignore_index=True)\n",
    "lehd_naics.to_csv('../Temp/lehd_naics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254903ae-4a31-41c7-b5b4-480b40f7206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ind_name to each dataframe, and group dataframes by FIPS code if they have employment from multiple NAICS codes\n",
    "#  Hospital and outpatient\n",
    "lehd_hosp['ind_name'] = lehd_hosp.apply(lambda x: 'hospital', axis=1)\n",
    "lehd_outp['ind_name'] = lehd_outp.apply(lambda x: 'outpatient', axis=1)\n",
    "\n",
    "#  Schools\n",
    "lehd_school['ind_name'] = lehd_school.apply(lambda x: 'school', axis=1)\n",
    "\n",
    "#  Accommodation\n",
    "lehd_accom['ind_name'] = lehd_accom.apply(lambda x: 'accommodation', axis=1)\n",
    "\n",
    "#  Restaurants\n",
    "lehd_rest['ind_name'] = lehd_rest.apply(lambda x: 'restaurant', axis=1)\n",
    "\n",
    "#  Warehousing & storage\n",
    "lehd_ware = lehd_ware.groupby(by='FIPS', as_index=False).sum()\n",
    "lehd_ware['ind_name'] = lehd_ware.apply(lambda x: 'warehouse_storage', axis=1)\n",
    "\n",
    "#  Retail\n",
    "lehd_retail['ind_name'] = lehd_retail.apply(lambda x: 'retail', axis=1)\n",
    "\n",
    "#  Office\n",
    "lehd_off = lehd_off.groupby(by='FIPS', as_index=False).sum()\n",
    "lehd_off['ind_name'] = lehd_off.apply(lambda x: 'office', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41417b03-7bf5-41de-9793-7277996405b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all employment data into one dataframe\n",
    "lehd_dfs = [lehd_hosp, lehd_outp, lehd_school, lehd_accom,\n",
    "            lehd_rest, lehd_ware, lehd_retail, lehd_off]\n",
    "lehd_emp = pd.concat(lehd_dfs, ignore_index=True)[['FIPS', 'Emp', 'ind_name']]\n",
    "\n",
    "# Compute total commercial employment per county (to merge onto totals dataframe)\n",
    "lehd_dfs_totals = [lehd_hosp, lehd_outp, lehd_school,\n",
    "                   lehd_accom_food, lehd_ware1, lehd_retail, lehd_off_excl_wholesale]\n",
    "lehd_emp_totals = pd.concat(lehd_dfs_totals, ignore_index=True)[['FIPS', 'Emp', 'ind_name']]\n",
    "lehd_total = lehd_emp.groupby(by='FIPS', as_index=False).sum()\n",
    "\n",
    "# lehd_emp.to_csv('../Temp/lehd_comm_buildtypes.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e2d7dfb-c7e9-4714-b795-3a5632da92ec",
   "metadata": {},
   "source": [
    "### 3.2.2 Compute emissions per employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b148bfcf-8696-4836-a52d-d75126066a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge employment data onto emissions data\n",
    "comm_dfs_final = comm_dfs_pop.copy()\n",
    "\n",
    "comm_dfs_final['indtype'] = pd.merge(\n",
    "    comm_dfs_final['indtype'], lehd_emp, how='left', on=['FIPS', 'ind_name'])\n",
    "comm_dfs_final['total'] = pd.merge(comm_dfs_final['total'], lehd_total, how='left', on=['FIPS'])\n",
    "\n",
    "# Understand how many counties have missing data\n",
    "print('Total number of datapoints:', len(comm_dfs_final['indtype']))\n",
    "print('Number of datapoints with NaN employment:', len(\n",
    "    comm_dfs_final['indtype'][~(comm_dfs_final['indtype']['Emp'] >= 0)]))\n",
    "print('Percent of datapoints with NaN employment:',\n",
    "      np.round(len(comm_dfs_final['indtype'][~(comm_dfs_final['indtype']\n",
    "               ['Emp'] >= 0)]) / len(comm_dfs_final['indtype']) * 100, 2),\n",
    "      '%')\n",
    "print('Percent of emissions with NaN employment:',\n",
    "      np.round(comm_dfs_final['indtype'][~(comm_dfs_final['indtype']['Emp'] >= 0)]['tonCO2e_total_w'].sum(\n",
    "      ) / comm_dfs_final['indtype']['tonCO2e_total_w'].sum() * 100, 2),\n",
    "      '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73338e24-35dc-4a79-8ffd-cfe7fb50dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate emissions per employee\n",
    "for df in ['indtype', 'total']:\n",
    "    #  Set employment in counties where it is reported to be 0 to NaN, as there must be employment there if there are emissions\n",
    "    comm_dfs_final[df]['Emp'] = comm_dfs_final[df].apply(\n",
    "        lambda x: np.nan if x.Emp == 0 else x.Emp, axis=1)\n",
    "\n",
    "    comm_dfs_final[df]['lbCO2e_peremp_w'] = comm_dfs_final[df].apply(\n",
    "        lambda x: x.lbCO2e_total_w / x.Emp if x.Emp > 0 else -1, axis=1)\n",
    "    comm_dfs_final[df]['tonCO2e_peremp_w'] = comm_dfs_final[df].apply(\n",
    "        lambda x: x.tonCO2e_total_w / x.Emp if x.Emp > 0 else -1, axis=1)\n",
    "\n",
    "    comm_dfs_final[df]['lbCO2e_peremp_w_log10'] = np.log10(comm_dfs_final[df]['lbCO2e_peremp_w'])\n",
    "    comm_dfs_final[df]['tonCO2e_peremp_w_log10'] = np.log10(comm_dfs_final[df]['tonCO2e_peremp_w'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa1b62b-d1a6-462a-b978-dfd56cc0959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualization purposes, compute the log10 of total weighted tonCO2e for every entry in each dataframe\n",
    "for df in comm_dfs_final.keys():\n",
    "    comm_dfs_final[df]['tonCO2e_total_w_log10'] = np.log10(comm_dfs_final[df]['tonCO2e_total_w'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eee3e3de-ee8b-4b80-92a2-ae753d782141",
   "metadata": {},
   "source": [
    "# 5 Write final dataframe to csv for overall analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d113051b-d7e8-46e7-8dff-d0e792cb1779",
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_dfs_final['total'].to_csv('../Output/comm_totalCO2_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
