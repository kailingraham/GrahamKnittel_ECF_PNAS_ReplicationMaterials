{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0674bed-c1fa-45c7-bfcf-e25afabcc3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "import math\n",
    "from scipy.stats.mstats import winsorize\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Load in a GeoJSON file containing the geometry information for US counties, where feature.id is a FIPS code.\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "\n",
    "with urlopen(\"https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json\") as response:\n",
    "    counties = json.load(response)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7dfeb61-bbe7-4432-b4b2-8301381f54d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1 Consolidate emissions data from other analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aa55e6-ad50-4cca-842a-5f269daf236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stateFIPS = pd.read_csv(\n",
    "    \"../Temp/stateFIPS.csv\",\n",
    "    dtype={\"FIPS\": str}\n",
    ").drop(columns=\"State\").rename(\n",
    "    columns={\"Abbr\": \"State\", \"FIPS\": \"FIPSTATE\"}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edcd25e2-70fd-432b-aa62-adf33f627b21",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 Industrial energy data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18beb479-d926-4db1-bf52-d7f84ab51d57",
   "metadata": {},
   "source": [
    "### 1.1.1 Read in all industrial energy csv files, store in dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f514458-2edf-4caf-8e7e-ae3d7b8bef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dictionary to store all dataframes\n",
    "emissions_raw = {}\n",
    "\n",
    "# use glob to get all the csv files in the folder\n",
    "path = os.getcwd() + \"\\..\\..\\..\\Data\\industrial\\Output\"\n",
    "csv_files = glob.glob(os.path.join(path, \"*_peremp_final.csv\"))\n",
    "\n",
    "# loop over the list of csv files\n",
    "for f in csv_files:\n",
    "\n",
    "    filename = f.replace(path + \"\\\\\", \"\").replace(\"_peremp_final.csv\", \"\")\n",
    "    print(filename)\n",
    "    # read the csv file\n",
    "    df = pd.read_csv(f, dtype={\"FIPS\": str, \"FIPSTATE\": str, \"STATEFIPS\": str, \"NAICS\": str}\n",
    "                     ).drop(columns=\"Unnamed: 0\")\n",
    "\n",
    "    # add the dataframe to the emissions dictionary\n",
    "    emissions_raw[filename] = df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb29af69-532e-4946-acc9-00f9f482a5cb",
   "metadata": {},
   "source": [
    "### 1.1.2 Define function to extract a specific dataframe from this dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6775d012-12bc-4d09-b616-5739ed2cadc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndustrialData(industry, granularity, category):\n",
    "    \"\"\"\n",
    "    Returns the final dataframe for a given set of specifications, as derived in the analysis \n",
    "    scripts using NREL's Industrial Energy DataBook dataset. Takes inputs and navigates through\n",
    "     dictionary computed above. All dataframes have absolute, per capita (including population)\n",
    "      and per employee (including no. employees) data.\n",
    "    -----------------------------------\n",
    "    Parameters:\n",
    "        industry (str): one of 'ag' (agriculture), 'cn' (construction), 'mn' (mining) or 'mf' (manufacturing).\n",
    "        granularity (str): one of '2dig', 'agg', or '6dig'. Indicates the NAICS subsector granularity\n",
    "                    required. 'agg' is generally 3- or 4-digit granularity, depending on the dataframe.\n",
    "        category (str): one of 'fuels', 'scopes', or 'totals'. 'fuels' returns data from each fuel source, \n",
    "                    'scopes' splits data into scope 1 and scope 2 emissions, and 'totals' returns total \n",
    "                    emissions (i.e. scope 1 + scope 2).\n",
    "\n",
    "    \"\"\"\n",
    "    filename = f\"{industry}_{granularity}_{category}\"\n",
    "    return emissions_raw[filename]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38ad9541-6bc0-4bfe-8b40-f8d6fa2ad0bf",
   "metadata": {},
   "source": [
    "## 1.2 Commercial sector data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bfed3e-96ff-4207-aae8-4edda748a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_raw = pd.read_csv(\n",
    "    \"../../../Data/comm/Output/comm_totalCO2_final.csv\",\n",
    "    dtype={\"FIPS\": str, \"FIPSTATE\": str, \"STATEFIPS\": str},\n",
    ").drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee1b0d76-6a0d-47de-824b-388ee663e8c9",
   "metadata": {},
   "source": [
    "## 1.3 Power plants data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19903a8d-e1da-4ff3-933f-f76197fa60aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwr_raw = pd.read_csv(\n",
    "    \"../../../Data/pwr/Output/pwr_totalCO2_final.csv\",\n",
    "    dtype={\"FIPS\": str, \"FIPSTATE\": str, \"STATEFIPS\": str},\n",
    ").drop(columns=\"Unnamed: 0\")\n",
    "pwr_plants_raw = pd.read_csv(\n",
    "    \"../../../Data/pwr/Output/powerplant_emissions2019.csv\",\n",
    "    dtype={\"FIPS\": str, \"FIPSTATE\": str, \"STATEFIPS\": str},\n",
    ").drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b62fb20-4292-4628-a012-840975cae3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract crosswalk of counties to NERC regions, to be used later when assigning demand elasticities for different fuels used for power gen.\n",
    "fips_nerc_crosswalk = pwr_raw[[\"FIPS\", \"NERC Region\"]]\n",
    "\n",
    "# Create a crosswalk of states to NERC regions using fips_nerc_crosswalk. Note that some states have counties in several NERC regions\n",
    "# - use the NERC region with the greatest number of counties\n",
    "#  Add FIPSTATE column\n",
    "df = fips_nerc_crosswalk.copy()\n",
    "df['FIPSTATE'] = df.apply(lambda x: x.FIPS[:2], axis=1)\n",
    "fipstate_nerc_crosswalk = df.copy()\n",
    "\n",
    "#  Reduce df to the NERC Regions attributable to each state\n",
    "fipstate_nerc_crosswalk = fipstate_nerc_crosswalk[['FIPSTATE', 'NERC Region']\n",
    "                                                  ].drop_duplicates(ignore_index=True)\n",
    "\n",
    "#  Add count of number of counties in a given NERC Region for each state\n",
    "fipstate_nerc_crosswalk['no_counties'] = fipstate_nerc_crosswalk.apply(\n",
    "    lambda x: len(fips_nerc_crosswalk[(df.FIPSTATE == x.FIPSTATE) &\n",
    "                                      (df['NERC Region'] == x['NERC Region'])]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "#  Sort by this count, and drop duplicated FIPSTATE rows leaving only NERC region with most counties per state\n",
    "fipstate_nerc_crosswalk = fipstate_nerc_crosswalk.sort_values(\n",
    "    by=['FIPSTATE', 'no_counties'], ignore_index=True)\n",
    "fipstate_nerc_crosswalk = fipstate_nerc_crosswalk[[\n",
    "    'FIPSTATE', 'NERC Region']].drop_duplicates(subset='FIPSTATE', keep='last', ignore_index=True)\n",
    "\n",
    "# Where there are counties missing in fips_nerc_crosswalk, use the NERC region of the state from fipstate_nerc_crosswalk\n",
    "# Read in dataframe of all US counties\n",
    "fips = pd.read_csv('../Temp/fips.csv', encoding='unicode_escape',\n",
    "                   names=['FIPS', 'County', 'State name', 'State'], dtype={'FIPS': str})\n",
    "\n",
    "# Merge missing counties onto fips_nerc_crosswalk\n",
    "fips_nerc_crosswalk = pd.merge(\n",
    "    fips_nerc_crosswalk,\n",
    "    fips['FIPS'],\n",
    "    how='outer',\n",
    "    on='FIPS'\n",
    ")\n",
    "\n",
    "# Populate missing NERC fields with state-level NERC data\n",
    "fips_nerc_crosswalk['FIPSTATE'] = fips_nerc_crosswalk.apply(lambda x: x.FIPS[:2], axis=1)\n",
    "fips_nerc_crosswalk = pd.merge(\n",
    "    fips_nerc_crosswalk,\n",
    "    fipstate_nerc_crosswalk,\n",
    "    how='left',\n",
    "    on='FIPSTATE'\n",
    ")\n",
    "fips_nerc_crosswalk['NERC Region_x'] = fips_nerc_crosswalk.apply(\n",
    "    lambda x: x['NERC Region_x'] if type(x['NERC Region_x']) == str else x['NERC Region_y'],\n",
    "    axis=1\n",
    ")\n",
    "fips_nerc_crosswalk = fips_nerc_crosswalk.rename(\n",
    "    columns={'NERC Region_x': 'NERC Region'}).drop(columns=['NERC Region_y', 'FIPSTATE'])\n",
    "\n",
    "# Write to csv for future use\n",
    "fips_nerc_crosswalk.to_csv('../Temp/fips_nerc_crosswalk.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d52e261-a83a-4826-8882-62c2d039a14b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.4 Fossil fuel production data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "783bca72-a7b4-470f-856c-fe94331b78bb",
   "metadata": {},
   "source": [
    "### 1.4.1 Oil & Gas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5af95b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in aggregated WellDatabase data\n",
    "og_raw = pd.read_csv(\n",
    "    \"../../../Data/og/Output/og_totalCO2_final.csv\",\n",
    "    dtype={\"FIPS\": str, \"FIPSTATE\": str, \"STATEFIPS\": str},\n",
    ").drop(columns=\"Unnamed: 0\")\n",
    "\n",
    "# Merge county names used in other analyses onto og_raw for consistency\n",
    "#  Read in county fips labels [NOTE: this file has been edited from that used in other code to ensure county names and their formatting match]\n",
    "fips = pd.read_csv(\"../Temp/fips_edited.csv\",\n",
    "                   encoding=\"windows-1252\",\n",
    "                   usecols=[1, 2, 3, 4],\n",
    "                   names=[\"FIPS\", \"County\", \"State Name\", \"State\"],\n",
    "                   dtype={\"FIPS\": str},\n",
    "                   )\n",
    "fips[\"County\"] = fips[\"County\"].str.lower()\n",
    "\n",
    "#  Drop existing county names\n",
    "og_raw = og_raw.drop(columns=\"County\")\n",
    "\n",
    "#  Merge on new county names\n",
    "og_raw = pd.merge(og_raw, fips[[\"FIPS\", \"County\"]], how=\"left\", on=\"FIPS\")\n",
    "\n",
    "# Convert everything into tonCO2e\n",
    "cols_to_convert = [\"em_gas_county (lbCO2e)\", \"em_oil_county (lbCO2e)\", \"em_total_county (lbCO2e)\"]\n",
    "\n",
    "og_raw[\"tonCO2e_gas\"] = og_raw[\"em_gas_county (lbCO2e)\"] / 2000\n",
    "og_raw[\"tonCO2e_oil\"] = og_raw[\"em_oil_county (lbCO2e)\"] / 2000\n",
    "og_raw[\"tonCO2e\"] = og_raw[\"em_total_county (lbCO2e)\"] / 2000\n",
    "og_raw = og_raw.drop(columns=cols_to_convert)\n",
    "\n",
    "# Rename necessary columns\n",
    "og_raw = og_raw.rename(columns={\"annual_avg_emplvl\": \"Emp\",\n",
    "                                \"Population\": \"POP\",\n",
    "                                \"short ton CO2/employee\": \"tonCO2e_peremp\"}\n",
    "                       )\n",
    "og_raw[\"FIPSTATE\"] = og_raw.apply(lambda x: x.FIPS[:2], axis=1)\n",
    "\n",
    "# Add column containing 'scope3' for all entries\n",
    "og_raw[\"scope\"] = og_raw.apply(lambda x: \"scope3\", axis=1)\n",
    "\n",
    "# If Emp == 0 but tonCO2e > 0, set Emp to NaN\n",
    "og_raw['Emp'] = og_raw.apply(lambda x: np.nan if (x.tonCO2e > 0 and x.Emp == 0) else x.Emp, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbd7f72d-0b88-4fa1-81a1-118001bf21a5",
   "metadata": {},
   "source": [
    "### 1.4.2 Coal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199a3a2e-4b60-44c4-9b36-d90e9fd71e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "coal_raw = pd.read_csv(\n",
    "    \"../../../Data/coal/Output/county_emissions_coal.csv\",\n",
    "    dtype={\"FIPS\": str, \"FIPSTATE\": str, \"STATEFIPS\": str},\n",
    ")\n",
    "\n",
    "# Merge state abbreviation and updated county name onto dataframe\n",
    "coal_raw = pd.merge(\n",
    "    coal_raw.drop(columns=[\"Mine County\", \"Mine State\"]),\n",
    "    fips[[\"FIPS\", \"County\"]],\n",
    "    how=\"left\",\n",
    "    on=\"FIPS\",\n",
    ")\n",
    "coal_raw[\"FIPSTATE\"] = coal_raw.apply(lambda x: x.FIPS[:2], axis=1)\n",
    "coal_raw = pd.merge(coal_raw, stateFIPS, how=\"left\", on=\"FIPSTATE\")\n",
    "\n",
    "# Rename necessary columns\n",
    "coal_raw = coal_raw.rename(columns={\"short ton CO2\": \"tonCO2e\",\n",
    "                                    \"Average Employees\": \"Emp\",\n",
    "                                    \"short ton CO2/employee\": \"tonCO2e_peremp\",\n",
    "                                    \"Population\": \"POP\",\n",
    "                                    \"short ton CO2/county pop\": \"tonCO2e_percapita\"}\n",
    "                           )\n",
    "\n",
    "# Add column containing 'scope3' for all entries\n",
    "coal_raw[\"scope\"] = coal_raw.apply(lambda x: \"scope3\", axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db3ab384-3f0e-40dc-b6dc-f95a408d1e4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2 Create dataframes for analysis and plotting\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee29e874-ced4-4f82-a5af-2d066ba6e560",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.1 Read in and consolidate data from each of the sectoral analyses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dcff9c-2596-4e67-b22a-b29f314aa565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify cols to keep in each dataframe\n",
    "cols_to_keep = {\n",
    "    \"ag\":   [\"FIPS\", \"FIPSTATE\", \"County\", \"STATE\", \"scope\", \"tonCO2e\", \n",
    "             \"Emp\", \"tonCO2e_Diesel\", \"tonCO2e_LPG_NGL\", \"tonCO2e_Net_electricity\", \"tonCO2e_Other\",\n",
    "             \"tonCO2e_Residual_fuel_oil\", \"tonCO2e_Natural_gas\", \"tonCO2e_Coal\"],\n",
    "    \"cn\":   [\"FIPS\", \"FIPSTATE\", \"County\", \"STATE\", \"scope\", \"tonCO2e\", \n",
    "             \"Emp\", \"tonCO2e_Diesel\", \"tonCO2e_LPG_NGL\", \"tonCO2e_Natural_gas\", \"tonCO2e_Net_electricity\"],\n",
    "    \"comm\": [\"State\", \"FIPS\", \"STATEFIPS\", \"County\", \"lbCO2e_elec_total_w\", \"tonCO2e_total_w\",\n",
    "             \"POP\", \"Emp\", \"lbCO2e_ng_total_w\", \"lbCO2e_other_total_w\", \"lbCO2e_dist_heat_w\",\n",
    "             \"lbCO2e_dist_cool_w\"],\n",
    "    \"mf\":   [\"FIPS\", \"FIPSTATE\", \"County\", \"STATE\", \"scope\", \"tonCO2e\",\n",
    "             \"Emp\", \"tonCO2e_Coal\", \"tonCO2e_Coke_and_breeze\", \"tonCO2e_Diesel\", \"tonCO2e_LPG_NGL\",\n",
    "             \"tonCO2e_Natural_gas\", \"tonCO2e_Net_electricity\", \"tonCO2e_Other\", \"tonCO2e_Residual_fuel_oil\"],\n",
    "    \"mn\":   [\"FIPS\", \"FIPSTATE\", \"NAICS\", \"County\", \"scope\", \"tonCO2e\", \n",
    "             \"Emp\", \"tonCO2e_Coal\", \"tonCO2e_Diesel\", \"tonCO2e_Natural_gas\", \"tonCO2e_Net_electricity\",\n",
    "             \"tonCO2e_Other\", \"tonCO2e_Residual_fuel_oil\", \"tonCO2e_LPG_NGL\"],\n",
    "    \"pwr\":  [\"FIPS\", \"County\", \"State\", \"Tons of CO2 Emissions\", \n",
    "             \"emp_new\", \"tonCO2e_PET\", \"tonCO2e_GAS\", \"tonCO2e_COAL\", \"tonCO2e_other\"],\n",
    "    \"og\":   [\"FIPS\", \"FIPSTATE\", \"County\", \"scope\", \"tonCO2e\",  \n",
    "             \"Emp\", \"tonCO2e_gas\", \"tonCO2e_oil\"],\n",
    "    \"coal\": [\"FIPS\", \"FIPSTATE\", \"County\", \"scope\", \"tonCO2e\", \"Emp\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ee248-50b9-47e7-bf8f-defaca884553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate O&G extraction and coal mining scope 1 and scope 2 emissions from NAICS subsector dataframe\n",
    "#  Read in subsector data from NREL IET\n",
    "df = getIndustrialData(\"mn\", \"agg\", \"scopes\")[cols_to_keep[\"mn\"]]\n",
    "df[\"tonCO2e_dsl\"] = (df[\"tonCO2e_Diesel\"] + df[\"tonCO2e_Other\"])  # treat 'other' as diesel\n",
    "df = df.drop(columns=[\"tonCO2e_Diesel\", \"tonCO2e_Other\"])\n",
    "df = df.rename(columns={\"tonCO2e_LPG_NGL\": \"tonCO2e_lpg\",\n",
    "                        \"tonCO2e_Net_electricity\": \"tonCO2e_elec\",\n",
    "                        \"tonCO2e_Residual_fuel_oil\": \"tonCO2e_residfuel\",\n",
    "                        \"tonCO2e_Natural_gas\": \"tonCO2e_ng\",\n",
    "                        \"tonCO2e_Coal\": \"tonCO2e_coal\"}\n",
    "               )\n",
    "\n",
    "#  Split up dataframe\n",
    "og_scope12 = df[df[\"NAICS\"] == \"2111\"]\n",
    "coal_scope12 = df[df[\"NAICS\"] == \"2121\"]\n",
    "mn_rem_scope12_subsect = df[(df[\"NAICS\"] != \"2111\") & (df[\"NAICS\"] != \"2121\")]\n",
    "\n",
    "# Concatenate O&G extraction and coal mining scope 1/2 emissions dataframes with scope 3 dataframes\n",
    "coal_scopes = pd.concat([coal_raw[cols_to_keep[\"coal\"]], coal_scope12], ignore_index=False)\n",
    "coal_scopes[\"tonCO2e_coal\"] = coal_scopes.apply(lambda x: x.tonCO2e\n",
    "                                                if x.scope == \"scope3\" else x.tonCO2e_coal, axis=1)\n",
    "og_scopes = pd.concat([og_raw[cols_to_keep[\"og\"]].rename(columns={\"tonCO2e_gas\": \"tonCO2e_ng\", \"tonCO2e_oil\": \"tonCO2e_crude\"}),\n",
    "                       og_scope12], ignore_index=False)\n",
    "\n",
    "# Merge employment data from scope 3 dataframes onto this new dataframe, as the employent data for coal mining and O&G extraction is more accurate\n",
    "coal_scopes = pd.merge(coal_scopes, coal_raw[[\"FIPS\", \"Emp\"]], how=\"left\", on=\"FIPS\")\n",
    "og_scopes = pd.merge(og_scopes, og_raw[[\"FIPS\", \"Emp\"]], how=\"left\", on=\"FIPS\")\n",
    "#  Keep employment data from scope 3, or scope 1/2 if no scope 3 employment available\n",
    "coal_scopes[\"Emp\"] = coal_scopes.apply(lambda x: x.Emp_y if x.Emp_y > 0 else x.Emp_x, axis=1)\n",
    "coal_scopes = coal_scopes.drop(columns=[\"Emp_x\", \"Emp_y\"])\n",
    "og_scopes[\"Emp\"] = og_scopes.apply(lambda x: x.Emp_y if x.Emp_y > 0 else x.Emp_x, axis=1)\n",
    "og_scopes = og_scopes.drop(columns=[\"Emp_x\", \"Emp_y\"])\n",
    "\n",
    "# Fixed isolated error cases\n",
    "og_scopes.loc[132, 'Emp'] = og_scopes.loc[1723,'Emp']\n",
    "og_scopes.loc[25, 'Emp'] = og_scopes.loc[2072,'Emp']\n",
    "og_scopes.loc[315, 'Emp'] = og_scopes.loc[2108,'Emp']\n",
    "\n",
    "# Add sector column\n",
    "coal_scopes[\"sector\"] = \"coal\"\n",
    "og_scopes[\"sector\"] = \"og\"\n",
    "\n",
    "# Add state column\n",
    "coal_scopes = pd.merge(coal_scopes, stateFIPS, how=\"left\", on=\"FIPSTATE\")\n",
    "og_scopes = pd.merge(og_scopes, stateFIPS, how=\"left\", on=\"FIPSTATE\")\n",
    "\n",
    "# Concatenate these dataframes together\n",
    "ff_scopes = pd.concat([coal_scopes, og_scopes]).drop(columns=\"NAICS\")\n",
    "ff_scopes.to_csv('../Temp/ff_scopes.csv')\n",
    "\n",
    "#  Isolate employment data from this final dataframe\n",
    "ff_scopes_emp = ff_scopes[[\"FIPS\", \"Emp\", \"sector\"]]#.drop_duplicates(ignore_index=True)\n",
    "ff_scopes_emp = pd.pivot_table(ff_scopes_emp, index=\"FIPS\", columns=\"sector\", values=\"Emp\"\n",
    "                               ).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55e4a7c-34b6-444c-aad2-bd9f34948070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for the mining emissions NOT associated with O&G extraction or coal mining\n",
    "#  Group the dataframe of mining subsectors (excluding coal mining and O&G extraction) to aggregate emissions from the remaining subsectors\n",
    "mn_rem_scope12 = mn_rem_scope12_subsect.drop(columns=\"Emp\").groupby(\n",
    "    by=[\"FIPS\", \"scope\", \"FIPSTATE\", \"County\"], as_index=False).sum(numeric_only=True)\n",
    "\n",
    "mn_rem_scope12 = pd.merge(mn_rem_scope12, stateFIPS, how=\"left\", on=\"FIPSTATE\")\n",
    "mn_rem_scope12[\"sector\"] = \"mn_rest\"\n",
    "\n",
    "#  Calculate employment for the remaining subsectors by pulling total mining employment data and subtracting the employment data for O&G extration and coal mining from this\n",
    "mn_rem_scope12_emp = getIndustrialData(\"mn\", \"2dig\", \"scopes\"\n",
    "                                       )[[\"FIPS\", \"Emp\"]].drop_duplicates(ignore_index=True)\n",
    "mn_rem_emp_final = pd.merge(mn_rem_scope12_emp,\n",
    "                            ff_scopes_emp,\n",
    "                            how=\"left\",\n",
    "                            on=\"FIPS\"\n",
    "                            ).rename(columns={\"Emp\": \"mn_total\"})\n",
    "mn_rem_emp_final[\"Emp\"] = mn_rem_emp_final.mn_total.fillna(0) - \\\n",
    "    mn_rem_emp_final.coal.fillna(0) - mn_rem_emp_final.og.fillna(0)\n",
    "\n",
    "mn_rem_emp_final[\"Emp\"] = mn_rem_emp_final.apply(\n",
    "    lambda x: np.nan if (np.isnan(x.mn_total)) else x.Emp, axis=1\n",
    ")\n",
    "mn_rem_emp_final[\"Emp\"] = mn_rem_emp_final.apply(\n",
    "    lambda x: np.nan if x.Emp < 0 else x.Emp, axis=1\n",
    ")\n",
    "\n",
    "#  Merge this calculated employment onto the dataframe of emissions for the remaining mining subsectors\n",
    "mn_rem_scope12 = pd.merge(mn_rem_scope12,\n",
    "                          mn_rem_emp_final[[\"FIPS\", \"Emp\"]],\n",
    "                          how=\"left\",\n",
    "                          on=\"FIPS\"\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9bd79c-4d74-4ee1-9942-bd77e6724c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary to hold all 'scope' dataframes\n",
    "scp_dict = {\"scope1\": {}, \"scope2\": {}, \"scope3\": {}}\n",
    "\n",
    "# For mining data, split into 3 sectors: coal mining, O&G extraction, and remaining mining activities. The first two will have scope 1, 2, 3 emissions, the last will have just scope 1 and 2\n",
    "for scope in [\"scope1\", \"scope2\", \"scope3\"]:\n",
    "    scp_dict[scope][\"coal\"] = ff_scopes[(ff_scopes[\"sector\"] == \"coal\") &\n",
    "                                        (ff_scopes[\"scope\"] == scope)]\n",
    "    scp_dict[scope][\"og\"] = ff_scopes[(ff_scopes[\"sector\"] == \"og\") &\n",
    "                                      (ff_scopes[\"scope\"] == scope)]\n",
    "    scp_dict[scope][\"mn_rest\"] = mn_rem_scope12[(mn_rem_scope12[\"sector\"] == \"mn_rest\") &\n",
    "                                                (mn_rem_scope12[\"scope\"] == scope)]\n",
    "\n",
    "# Read in necessary remaining industrial data, reformat, and add to dictionary\n",
    "for ind in [\"ag\", \"cn\", \"mf\"]:\n",
    "    df = getIndustrialData(ind, \"2dig\", \"scopes\")[cols_to_keep[ind]]\n",
    "    df = pd.merge(df, stateFIPS, how=\"left\", on=\"FIPSTATE\").drop(columns=\"STATE\")\n",
    "    df[\"sector\"] = ind\n",
    "\n",
    "    #  Set up all necessary columns for emissions by fuel type\n",
    "    fuel_em_cols = [\"tonCO2e_Coal\", \"tonCO2e_Coke_and_breeze\", \"tonCO2e_Diesel\", \"tonCO2e_LPG_NGL\",\n",
    "                    \"tonCO2e_Natural_gas\", \"tonCO2e_Net_electricity\", \"tonCO2e_Other\", \"tonCO2e_Residual_fuel_oil\"]\n",
    "    for col in fuel_em_cols:\n",
    "        if col not in list(df.columns):\n",
    "            df[col] = np.zeros(len(df))\n",
    "\n",
    "    #  Assign fuel emissions that don't fit into one of the main categories to main categories\n",
    "    df[\"tonCO2e_dsl\"] = df[\"tonCO2e_Diesel\"] + df[\"tonCO2e_Other\"]  # treat 'other' as diesel\n",
    "    df[\"tonCO2e_coal\"] = df[\"tonCO2e_Coal\"] + \\\n",
    "        df[\"tonCO2e_Coke_and_breeze\"]  # treat coke and breeze as coal\n",
    "\n",
    "    #  Drop unnecessary columns and rename to match other sectors\n",
    "    df = df.drop(columns=[\"tonCO2e_Diesel\",\n",
    "                          \"tonCO2e_Other\",\n",
    "                          \"tonCO2e_Coal\",\n",
    "                          \"tonCO2e_Coke_and_breeze\",\n",
    "                          ]\n",
    "                 )\n",
    "    df = df.rename(columns={\"tonCO2e_LPG_NGL\": \"tonCO2e_lpg\",\n",
    "                            \"tonCO2e_Net_electricity\": \"tonCO2e_elec\",\n",
    "                            \"tonCO2e_Residual_fuel_oil\": \"tonCO2e_residfuel\",\n",
    "                            \"tonCO2e_Natural_gas\": \"tonCO2e_ng\",\n",
    "                            }\n",
    "                   )\n",
    "\n",
    "    #  Split dataframe into scope 1 and scope 2, and assign to corresponding dictionary\n",
    "    scp_dict[\"scope1\"][ind] = df[df[\"scope\"] == \"scope1\"]\n",
    "    scp_dict[\"scope1\"][ind][\"sector\"] = ind\n",
    "\n",
    "    scp_dict[\"scope2\"][ind] = df[df[\"scope\"] == \"scope2\"]\n",
    "    scp_dict[\"scope2\"][ind][\"sector\"] = ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9928ff41-f0fc-40d5-9872-e4a415dcc6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat commercial data and add to dictionary\n",
    "#  Isolate desired columns from raw data\n",
    "df = comm_raw[cols_to_keep[\"comm\"]].copy()\n",
    "\n",
    "#  Rename emissions by fuel type to be in keeping with the other sectors\n",
    "df[\"tonCO2e_ng1\"] = df[\"lbCO2e_ng_total_w\"] / 2000\n",
    "df[\"tonCO2e_elec1\"] = df[\"lbCO2e_elec_total_w\"] / 2000\n",
    "df[\"tonCO2e_heatoil\"] = df[\"lbCO2e_other_total_w\"] / 2000  # treat 'other' as heating oil\n",
    "df[\"tonCO2e_ng2\"] = df[\"lbCO2e_dist_heat_w\"] / 2000  # treat as natural gas consumption\n",
    "df[\"tonCO2e_elec2\"] = df[\"lbCO2e_dist_cool_w\"] / 2000  # treat as electrcitiy consumption\n",
    "df[\"tonCO2e_ng\"] = df[\"tonCO2e_ng1\"] + df[\"tonCO2e_ng2\"]\n",
    "df[\"tonCO2e_elec\"] = df[\"tonCO2e_elec1\"] + df[\"tonCO2e_elec2\"]\n",
    "\n",
    "df[\"sector\"] = \"comm\"\n",
    "\n",
    "#  Split into scope 1 and scope 2\n",
    "comm_scope1 = df.copy()\n",
    "comm_scope2 = df.copy()\n",
    "\n",
    "# Scope 1\n",
    "#  Calculate scope 1 emissions by subtracting electricity emissions (i.e. scope 2 emissions) from total emissions\n",
    "comm_scope1[\"tonCO2e\"] = comm_scope1[\"tonCO2e_total_w\"] - comm_scope1[\"tonCO2e_elec\"]\n",
    "\n",
    "#  Set electricity emissions to 0 (as for the scope 1 emissions dataframe electricity should not be accounted for)\n",
    "comm_scope1[\"tonCO2e_elec\"] = np.zeros(len(comm_scope1))\n",
    "\n",
    "#  Drop unnecessary columns, and add to dictionary\n",
    "scp_dict[\"scope1\"][\"comm\"] = comm_scope1.rename(columns={\"STATEFIPS\": \"FIPSTATE\"}).drop(\n",
    "    columns=[\n",
    "        \"tonCO2e_total_w\",\n",
    "        \"lbCO2e_elec_total_w\",\n",
    "        \"POP\",\n",
    "        \"lbCO2e_ng_total_w\",\n",
    "        \"lbCO2e_other_total_w\",\n",
    "        \"lbCO2e_dist_heat_w\",\n",
    "        \"lbCO2e_dist_cool_w\",\n",
    "        \"tonCO2e_ng1\",\n",
    "        \"tonCO2e_ng2\",\n",
    "        \"tonCO2e_elec1\",\n",
    "        \"tonCO2e_elec2\",\n",
    "    ]\n",
    ")\n",
    "# Scope 2\n",
    "#  Calculate scope 2 emissions as just the total electricity consumption. Set all other fuel emissions to 0.\n",
    "comm_scope2[\"tonCO2e\"] = comm_scope2[\"tonCO2e_elec\"]\n",
    "comm_scope2[\"tonCO2e_heatoil\"] = np.zeros(len(comm_scope2))\n",
    "comm_scope2[\"tonCO2e_ng\"] = np.zeros(len(comm_scope2))\n",
    "\n",
    "#  Drop unnecessary columns, and add to dictionary\n",
    "scp_dict[\"scope2\"][\"comm\"] = comm_scope2.rename(columns={\"STATEFIPS\": \"FIPSTATE\"}).drop(\n",
    "    columns=[\n",
    "        \"tonCO2e_total_w\",\n",
    "        \"lbCO2e_elec_total_w\",\n",
    "        \"POP\",\n",
    "        \"lbCO2e_ng_total_w\",\n",
    "        \"lbCO2e_other_total_w\",\n",
    "        \"lbCO2e_dist_heat_w\",\n",
    "        \"lbCO2e_dist_cool_w\",\n",
    "        \"tonCO2e_ng1\",\n",
    "        \"tonCO2e_ng2\",\n",
    "        \"tonCO2e_elec1\",\n",
    "        \"tonCO2e_elec2\",\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068b31d4-3fbc-4039-93cf-0d160f34d262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat power plant data and add to dictionary (only scope 1, as assumed no scope 2)\n",
    "scp_dict[\"scope1\"][\"pwr\"] = pwr_raw[cols_to_keep[\"pwr\"]]\n",
    "# treat 'other' emissions as natural gas\n",
    "scp_dict[\"scope1\"][\"pwr\"][\"tonCO2e_ng\"] = scp_dict[\"scope1\"][\"pwr\"][\"tonCO2e_other\"] + \\\n",
    "    scp_dict[\"scope1\"][\"pwr\"][\"tonCO2e_GAS\"]\n",
    "\n",
    "#  Assume plants that use petroleum use residual fuel oil.\n",
    "scp_dict[\"scope1\"][\"pwr\"] = pd.merge(scp_dict[\"scope1\"][\"pwr\"],\n",
    "                                     stateFIPS,\n",
    "                                     how=\"left\",\n",
    "                                     on=\"State\"\n",
    "                                     ).rename(\n",
    "    columns={\"Tons of CO2 Emissions\": \"tonCO2e\",\n",
    "             \"emp_new\": \"Emp\",\n",
    "             \"tonCO2e_PET\": \"tonCO2e_residfuel\",\n",
    "             \"tonCO2e_COAL\": \"tonCO2e_coal\",\n",
    "             }\n",
    ")\n",
    "#  clean up columns, add sector column\n",
    "scp_dict[\"scope1\"][\"pwr\"] = scp_dict[\"scope1\"][\"pwr\"].drop(columns=[\"tonCO2e_other\", \"tonCO2e_GAS\"])\n",
    "scp_dict[\"scope1\"][\"pwr\"][\"sector\"] = \"pwr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92c59fd-dfb2-47f6-a551-892f091267ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each scope, merge into a single dataframe\n",
    "for scope in scp_dict.keys():\n",
    "    scp_dict[scope] = pd.concat(scp_dict[scope].values(), ignore_index=True)\n",
    "    scp_dict[scope][\"scope\"] = scope\n",
    "\n",
    "# Finally, concatenate each 'scope' entry in dictionary to obtain final master dataframe\n",
    "sector_scope = pd.concat(scp_dict.values(), ignore_index=True)\n",
    "\n",
    "# Fill NaNs in tonCO2e_{fuel} fields with 0s (as the reason they're NaN is because there was no consumption/production of that fuel)\n",
    "tonCO2e_perfuel_cols = [\"tonCO2e_coal\", \"tonCO2e_ng\", \"tonCO2e_elec\",\n",
    "                        \"tonCO2e_residfuel\", \"tonCO2e_lpg\", \"tonCO2e_dsl\", \"tonCO2e_crude\", \"tonCO2e_heatoil\"]\n",
    "sector_scope[tonCO2e_perfuel_cols] = sector_scope[tonCO2e_perfuel_cols].fillna(0)\n",
    "\n",
    "# Read in total county employment as extracted from LEHD\n",
    "%run ../../../Data/empData/Scripts/LEHD_API_pull.ipynb\n",
    "# total_county_emp_lehd = getLEHDemp('2018', '2', '00', write_to_csv = True)\n",
    "total_county_emp_lehd = pd.read_csv(\n",
    "    '../../../Data/empData/Temp/emp_ovr_00_2dig_2018.csv', \n",
    "    dtype={'state': str, 'county': str, 'FIPS': str, 'sex': str, 'year': str, 'industry': str}\n",
    ").drop(columns=['Unnamed: 0'])\n",
    "total_county_emp_lehd = total_county_emp_lehd[['FIPS', 'Emp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd72da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are several counties that have changed over the 2010s, and some of the datasources\n",
    "# use old county names while the overall employment data we use is up to date. Therefore,\n",
    "# need to ensure they are consistent. Should keep only the counties that have defined emissions\n",
    "# data - i.e. if these are the old county geographies, should use these ahead of updating and\n",
    "# losing data coverage for those areas.\n",
    "\n",
    "# Wrangell-Petersburg Census Area (02280) in Alaska split into Wrangell City and Borough (02275) and\n",
    "# Petersburg Census Area (02195). Emissions data is for 02280, therefore should back-calculate\n",
    "# employment for old county geography\n",
    "total_county_emp_lehd = pd.concat(\n",
    "    [total_county_emp_lehd,\n",
    "     pd.DataFrame(\n",
    "         [{'FIPS': '02280',\n",
    "          'Emp': total_county_emp_lehd[(total_county_emp_lehd.FIPS == '02275') |\n",
    "                                       (total_county_emp_lehd.FIPS == '02195')].Emp.sum()}],\n",
    "     )\n",
    "     ],\n",
    "    ignore_index=True\n",
    ")\n",
    "total_county_emp_lehd = total_county_emp_lehd[\n",
    "    (total_county_emp_lehd.FIPS != '02275') & (total_county_emp_lehd.FIPS != '02195')]\n",
    "\n",
    "# Bedford City (51515) was incorporated into Bedford County (51019). Have emissions data for both,\n",
    "# so incorporate Bedford City's emissions into Bedford County\n",
    "for i in range(len(sector_scope)):\n",
    "    if sector_scope.loc[i, 'FIPS'] == '51515':\n",
    "        sector_scope.loc[i, 'FIPS'] = '51019'\n",
    "        sector_scope.loc[i, 'County'] = 'bedford'\n",
    "sector_scope = sector_scope.groupby(\n",
    "    by=['FIPS', 'FIPSTATE', 'County', 'State', 'scope', 'sector'],\n",
    "    as_index=False\n",
    ").sum(numeric_only=True)\n",
    "sector_scope['Emp'] = sector_scope.Emp.replace(0, np.nan)\n",
    "\n",
    "# Skagway-Hoonah-Angoon Census Area (02232) was split into Skagway Municipality (02230) and\n",
    "# Hoonah-Angoon Census Area (02105). Emissions data is for Skagway-Hoonah-Angoon Census Area,\n",
    "# so back-calculate employment for old county geography\n",
    "pd.concat(\n",
    "    [total_county_emp_lehd,\n",
    "     pd.DataFrame(\n",
    "         [{'FIPS': '02232',\n",
    "          'Emp': total_county_emp_lehd[(total_county_emp_lehd.FIPS == '02230') |\n",
    "                                       (total_county_emp_lehd.FIPS == '02105')].Emp.sum()}],\n",
    "     )\n",
    "     ],\n",
    "    ignore_index=True\n",
    ")\n",
    "total_county_emp_lehd = total_county_emp_lehd[\n",
    "    (total_county_emp_lehd.FIPS != '02230') & (total_county_emp_lehd.FIPS != '02105')]\n",
    "\n",
    "# Valdez-Cordova Census Area (02261) was split into Chugach Census Area (02063) and Copper\n",
    "# River Census Area (02066). Emissions data is for Valdez-Cordova Census Area, therefore\n",
    "# back-calculate employment for old county geography\n",
    "pd.concat(\n",
    "    [total_county_emp_lehd,\n",
    "     pd.DataFrame(\n",
    "         [{'FIPS': '02261',\n",
    "          'Emp': total_county_emp_lehd[(total_county_emp_lehd.FIPS == '02063') |\n",
    "                                       (total_county_emp_lehd.FIPS == '02066')].Emp.sum()}],\n",
    "     )\n",
    "     ],\n",
    "    ignore_index=True\n",
    ")\n",
    "total_county_emp_lehd = total_county_emp_lehd[\n",
    "    (total_county_emp_lehd.FIPS != '02063') & (total_county_emp_lehd.FIPS != '02066')]\n",
    "\n",
    "# Prince of Wales-Outer Ketchikan Census Area (02201) was dissolved - part was absorbed into\n",
    "# Ketchikan Gateway Borough (02130) as \"Outer Ketchikan\" and the remainder formed Prince of\n",
    "# Wales-Hyder Census Area (02198). Emissions data is for Prince of Wales-Outer Ketchikan\n",
    "# Census Area, so back-calculate employment for old county geography.\n",
    "# Assume that employment in Outer Ketchikan is proportional to population.\n",
    "pop_outer_ketch, pop_02130 = 5729, 13754\n",
    "emp_outer_ketch = pop_outer_ketch / pop_02130 * \\\n",
    "    total_county_emp_lehd[total_county_emp_lehd.FIPS == '02130'].Emp.sum()\n",
    "\n",
    "pd.concat(\n",
    "    [total_county_emp_lehd,\n",
    "     pd.DataFrame(\n",
    "         [{'FIPS': '02201',\n",
    "          'Emp': total_county_emp_lehd[(total_county_emp_lehd.FIPS == '02198')].Emp.sum() + emp_outer_ketch}],\n",
    "     )\n",
    "     ],\n",
    "    ignore_index=True\n",
    ")\n",
    "total_county_emp_lehd = total_county_emp_lehd[(\n",
    "    total_county_emp_lehd.FIPS != '02198')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36ec7839-56b4-42fa-9e9e-da9eb274b714",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.2 Calculate tax burdens\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "477b7147",
   "metadata": {},
   "source": [
    "### 2.2.1 Read and reformat PED, price, and passthrough data necessary to perform burden calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e19fee4-da55-41b4-ac40-39e51cbdde89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in tax passthrough rates by fuel type\n",
    "fuel_elast = pd.read_excel(\"../Temp/fuel_elasticities_FINAL.xlsx\", usecols=\"A:P\")\n",
    "\n",
    "# Read in price data by fuel type and sector, and structure df in a mergeable format\n",
    "price_data = pd.read_excel('../Temp/EIA_price_data/price_data_clean.xlsx',\n",
    "                           sheet_name='Data',\n",
    "                           dtype={'FIPSTATE': str},\n",
    "                           usecols='A:P'\n",
    "                           )\n",
    "price_pivot_keys = pd.read_excel('../Temp/EIA_price_data/price_data_clean.xlsx',\n",
    "                                 sheet_name='Pivot_keys',\n",
    "                                 usecols='A:C'\n",
    "                                 )\n",
    "price_data = pd.melt(frame=price_data,\n",
    "                     id_vars=['STATE', 'FIPSTATE'],\n",
    "                     value_vars=list(price_pivot_keys.col_name),\n",
    "                     var_name='col_name',\n",
    "                     value_name='price'\n",
    "                     )\n",
    "price_data = pd.merge(price_data, price_pivot_keys, how='left', on='col_name')\n",
    "\n",
    "# Merge NERC region onto price df\n",
    "price_data = pd.merge(price_data, fipstate_nerc_crosswalk, how='left', on='FIPSTATE')\n",
    "\n",
    "# Need to convert these prices from physical units to tonCO2e. Create a dictionary containing the emissions\n",
    "# factors for different fuels (from https://www.eia.gov/environment/emissions/co2_vol_mass.php). Also, merge\n",
    "# the carbon intensities of electricity by county (derived from eGRID subregion carbon intensities in other\n",
    "# analyses) onto the price dataframe. Use these to derive final price per tonCO2e.\n",
    "\n",
    "# Read in electricity carbon intensity by county, convert to intensities per state, and merge onto price_data\n",
    "counties_elec_intensity = pd.read_csv('../../../Data/industrial/Temp/counties_elec_intensity.csv',\n",
    "                                      dtype={'id': str, 'STATE': str, 'COUNTY': str}\n",
    "                                      ).drop(columns='Unnamed: 0')\n",
    "counties_elec_intensity = counties_elec_intensity[['id', 'SRC2ERTA']\n",
    "                                                  ].rename(columns={'id': 'FIPS', 'SRC2ERTA': 'lbCO2e_perMWh_elec'})\n",
    "counties_elec_intensity['FIPSTATE'] = counties_elec_intensity['FIPS'].apply(lambda x: x[:2])\n",
    "state_elec_intensity = counties_elec_intensity[['FIPSTATE', 'lbCO2e_perMWh_elec']\n",
    "                                               ].groupby(by='FIPSTATE', as_index=False).mean()\n",
    "\n",
    "price_data = pd.merge(price_data, state_elec_intensity, how='left', on='FIPSTATE')\n",
    "\n",
    "# Create dictionary of carbon emission intensities for remaining energy products\n",
    "ef_dict = {'coal': 4933.59/2000,  # short tonCO2e/short ton coal, assume bituminous\n",
    "           'ng': 120.96/2000,  # short tonCO2e/Mcf NG\n",
    "           # tonCO2e/bbl = 1.10231 tonCO2e/tonneCO2e * tonneCO2e/Bbtu * 0.0058Bbtu/bbl\n",
    "           'crude': 1.10231 * 74.47 * 0.0058,\n",
    "           'dsl': 22.45/2000,  # short tonCO2e/gallon diesel\n",
    "           'heatoil': 22.45/2000,  # same as diesel\n",
    "           'lpg': 12.68/2000,  # short tonCO2e/gallon lpg\n",
    "           'residfuel': 24.78/2000,  # short tonCO2e/gallon residual fuel oil\n",
    "           }\n",
    "\n",
    "# Define a function that reads fuel type of each entry and performs the appropraite calculation\n",
    "def calc_price_pertonCO2e(fuel_type, ef_dict, price, lbCO2e_perMWh):\n",
    "    if fuel_type == 'elec':\n",
    "        price_pertonCO2e = price*10 * lbCO2e_perMWh/2000\n",
    "    else:\n",
    "        price_pertonCO2e = price / ef_dict[fuel_type]  # $/physunit / physunit/tonCO2e\n",
    "    return price_pertonCO2e\n",
    "\n",
    "# Apply function to price_data, and drop lbCO2e_perMWh_elec (don't need it anymore)\n",
    "price_data['price_pertonCO2e'] = price_data.apply(\n",
    "    lambda x: calc_price_pertonCO2e(x.fuel, ef_dict, x.price, x.lbCO2e_perMWh_elec),\n",
    "    axis=1\n",
    ")\n",
    "price_data = price_data.drop(columns='lbCO2e_perMWh_elec')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2b6e188-a9f6-40a3-a7d2-0936911474dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2.2 Burden on fossil fuel producers\n",
    "Fossil fuel producers will face different effective tax rates depending on the sector their customers are in (e.g. commercial consumption of natural gas is more elastic than industrial consumption, therefore we would expect the producer to bear a higher tax incidence when selling to commercial consumers than to industrial consumers). However, if we consider that all producers sell into the same national market, then we can average out the effective tax rates on producers, by summing the total quantity of a given fuel that sees the full carbon tax for each type of consumer (using that consumer's tax incidence) and dividing this by the total amount of fuel production. Perform this calculation for each fossil fuel produced. Note that the effective incidences discussed below are producer incidences (i.e. the burden on the fossil fuel producer = tax \\* incidences used here).\n",
    "\n",
    "<b>Coal</b><br>\n",
    "Calc\n",
    "Use the EIA's Coal Data Browser to identify the total annual consumption of coal across sectors (https://www.eia.gov/coal/data/browser/#/topic/20?agg=0,1&geo=g&sec=gs&linechart=COAL.CONS_TOT.US-98.A&columnchart=COAL.CONS_TOT.US-98.A&map=COAL.CONS_TOT.US-9.A&freq=A&start=2020&end=2021&ctype=map&ltype=pin&rtype=s&pin=&rse=0&maptype=0). Use 2020 data as that is the year used in the emissions calculations. Assumptions:\n",
    "\n",
    "- Treat all coal consumption that is not for power generation as 'industrial'\n",
    "- Assume that import/export elasticities of demand are the same as domestic industrial elasticities of demand\n",
    "\n",
    "<b>Natural gas</b><br>\n",
    "We can consider that natural gas produced in the US is either consumed by industry, commercial sectors, power generators, or is exported. Use the EIA's data for 2020 to determine quantities. Assumptions used for this calculation:\n",
    "\n",
    "- All natural gas that is not consumed commercially, industrially or for power generation is exported.\n",
    "- The PED of exported natural gas = PED of natural gas in international markets\n",
    "\n",
    "<b>Oil</b><br>\n",
    "We can consider oil produced in the US to be either exported as crude or sent to domestic refineries, where it is processed into different products (we will consider gasoline (for transport sector, not covered by our analysis), petroleum (for power generation), heating oil, and diesel). To determine the effective tax pass-through rate for all oil produced in the US, we need to make some assumptions about the price elasticities of demand for these products, as well as how taxes are passed through the refineries. The assumptions used for this calculation are as follows:\n",
    "\n",
    "- Price elasticity of demand for crude oil at US refineries is equal to the price elasticity of demand for crude oil on the global market.\n",
    "- Price elasticity of supply of each of the refined products is equal to the price elasticity of supply for gasoline.\n",
    "- Price elasticity of demand for crude oil exports = price elasticity of demand for oil on the global market\n",
    "\n",
    "Because we assume all oil is either exported or sent to US refineries, and we assume the PED of crude on the international market is the same as that at US refineries, the effective pass-through rate on US oil producers = the pass-through rate of oil on producers in the global market. To calculate the effective pass-through rate, we determine the total amount of crude (in tonCO2e) sent to US refineries and multiply this by the pass-through rate between oil producers and oil refineries. Note that the final result will be the percentage of any tax passed down to refineries - refineries will then pass down a percentage of that tax to consumers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3c47ea-0b95-4d84-8be8-a2a3378499d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EFFECTIVE PASSTHROUGH RATE FOR COAL PRODUCERS\n",
    "# US coal production (short tons coal)\n",
    "prod_coal = 535434354\n",
    "\n",
    "# Coal consumption\n",
    "cons_coal_ind = 793111 + 14413596 + 25659546  # Industrial consumption, short tons coal\n",
    "\n",
    "# for power plant consumption, multiply total power plant fossil fuel consumption by the relative emissions attributable to coal for each NERC region\n",
    "cons_coal_pwr_total = 435826849  # short tons coal\n",
    "cons_coal_by_nerc = pwr_raw[[\"NERC Region\", \"Tons of CO2 Emissions\", \"tonCO2e_COAL\"]\n",
    "                            ].groupby(by=\"NERC Region\", as_index=False).sum(numeric_only=True)\n",
    "cons_coal_by_nerc[\"coal_frac\"] = cons_coal_by_nerc[\"tonCO2e_COAL\"] / \\\n",
    "    cons_coal_by_nerc[\"tonCO2e_COAL\"].sum()\n",
    "cons_coal_by_nerc[\"cons_coal\"] = cons_coal_by_nerc[\"coal_frac\"] * cons_coal_pwr_total\n",
    "\n",
    "# Coal consumption pass-through fractions\n",
    "coal_elast = fuel_elast[(fuel_elast[\"fuel\"] == \"coal\")].copy()\n",
    "rho_elec = fuel_elast[(fuel_elast.sector == \"all\") &\n",
    "                      (fuel_elast.fuel == \"elec\")].rho_avg.mean()\n",
    "\n",
    "coal_cons_df = pd.merge(\n",
    "    coal_elast,\n",
    "    cons_coal_by_nerc[[\"NERC Region\", \"coal_frac\", \"cons_coal\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"nerc\",\n",
    "    right_on=[\"NERC Region\"],\n",
    ")\n",
    "\n",
    "# Fill in NaN field for industrial coal usage, and drop FRCC and SPP rows (as they are NaNs)\n",
    "coal_cons_df.loc[0, \"cons_coal\"] = cons_coal_ind\n",
    "coal_cons_df = coal_cons_df.drop([1, 6]).reset_index(drop=True)\n",
    "\n",
    "# Calculate effective quantity of coal produced by coal mines that sees the full carbon tax\n",
    "# For retail sectors, effective quantity seeing carbon tax is (1-rho) * Q\n",
    "coal_cons_df[\"taxed_coal\"] = coal_cons_df.apply(lambda x: (1-x.rho_avg) * x.cons_coal\n",
    "                                                if x.sector in [\"comm\", 'ind', 'res']\n",
    "                                                else np.nan,\n",
    "                                                axis=1\n",
    "                                                )\n",
    "\n",
    "# For power sector, effective quantity is (1-Id_pwr)*(1-rho_elec)*Q\n",
    "coal_cons_df[\"taxed_coal\"] = coal_cons_df.apply(lambda x: (1-x.Id_pwr_avg) * (1-rho_elec) * x.cons_coal\n",
    "                                                if x.sector == 'pwr'\n",
    "                                                else x.taxed_coal,\n",
    "                                                axis=1\n",
    "                                                )\n",
    "\n",
    "# Calculate effective producer pass-through on coal producers, as the effective quantity of US coal production that sees the full carbon tax / total US coal production\n",
    "rho_prod_coal_eff = coal_cons_df[\"taxed_coal\"].sum() / prod_coal\n",
    "rho_prod_coal_eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12555d7a-3f67-429f-ac46-4f6f2b2ae6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EFFECTIVE PASSTHROUGH RATE FOR NATURAL GAS PRODUCERS\n",
    "# NG production/consumption figures (units MMcf) (https://www.eia.gov/dnav/ng/ng_prod_sum_a_EPG0_FGW_mmcf_a.htm)\n",
    "prod_ng = 40613767\n",
    "\n",
    "# below from EIA consumption data: https://www.eia.gov/dnav/ng/ng_cons_sum_dcu_nus_a.htm\n",
    "cons_ng_res = 4674461\n",
    "cons_ng_comm = 3169955\n",
    "cons_ng_pwr = 11631723\n",
    "# Assume industrial = everything not residential, commercial or power sector\n",
    "cons_ng_ind = 30513453 - cons_ng_res - cons_ng_comm - cons_ng_pwr\n",
    "\n",
    "# Read in NG consumption pass-through rates, as well as electricity retail pass-through rate\n",
    "ng_elast = fuel_elast[(fuel_elast[\"fuel\"] == \"ng\")].copy()\n",
    "\n",
    "# To estimate NG consumption in power plants by NERC region, multiply total power plant fossil fuel consumption by the relative emissions attributable to gas for each NERC Region\n",
    "cons_ng_by_nerc = pwr_raw[[\"NERC Region\", \"Tons of CO2 Emissions\", \"tonCO2e_GAS\"]\n",
    "                          ].groupby(by=\"NERC Region\", as_index=False).sum(numeric_only=True)\n",
    "cons_ng_by_nerc[\"ng_frac\"] = cons_ng_by_nerc[\"tonCO2e_GAS\"] / cons_ng_by_nerc[\"tonCO2e_GAS\"].sum()\n",
    "cons_ng_by_nerc[\"cons_ng\"] = cons_ng_by_nerc[\"ng_frac\"] * cons_ng_pwr\n",
    "\n",
    "# Create dataframe containing all natural gas consumption pass-through rates for different sectors\n",
    "ng_cons_df = pd.merge(\n",
    "    ng_elast,\n",
    "    cons_ng_by_nerc[[\"NERC Region\", \"ng_frac\", \"cons_ng\"]],\n",
    "    how=\"left\",\n",
    "    right_on=[\"NERC Region\"],\n",
    "    left_on=\"nerc\",\n",
    ")\n",
    "\n",
    "# Drop NaN rows, and fill commercial, residential, industrial values for NG consumed with the values derived above\n",
    "ng_cons_df = ng_cons_df.drop([3, 8]).reset_index(drop=True)\n",
    "ng_cons_df.loc[0, \"cons_ng\"] = cons_ng_comm\n",
    "ng_cons_df.loc[1, \"cons_ng\"] = cons_ng_res\n",
    "ng_cons_df.loc[2, \"cons_ng\"] = cons_ng_ind\n",
    "\n",
    "# Calculate total quantity that sees full carbon tax for each sector\n",
    "# For retail sectors, effective quantity seeing carbon tax for producers is (1-rho) * Q\n",
    "ng_cons_df[\"taxed_ng\"] = ng_cons_df.apply(\n",
    "    lambda x: (1 - x.rho_avg) * x.cons_ng\n",
    "    if x.sector in [\"comm\", \"ind\", \"res\"] else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# For power sector, effective quantity for producers is (1-Id_pwr)*(1-rho_elec)*Q\n",
    "ng_cons_df[\"taxed_ng\"] = ng_cons_df.apply(\n",
    "    lambda x: (1 - x.Id_pwr_avg) * (1 - rho_elec) * x.cons_ng\n",
    "    if x.sector == \"pwr\"\n",
    "    else x.taxed_ng,\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "#  Calculate total effective taxed quantity and derive effective pass-through rate\n",
    "total_taxed = ng_cons_df[\"taxed_ng\"].sum()\n",
    "rho_prod_ng_eff = total_taxed / prod_ng\n",
    "rho_prod_ng_eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156d99b3-506d-4a38-bf4d-c1283615bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production data\n",
    "# Crude oil (https://www.eia.gov/dnav/pet/pet_crd_crpdn_adc_mbbl_a.htm). Units: thousand barrels\n",
    "crude_prod = 4142277\n",
    "\n",
    "# Refined product production data below from: https://www.eia.gov/dnav/pet/pet_cons_psup_dc_nus_mbbl_a.htm. Units: thousand barrels.\n",
    "gas_prod = 2946014  # Finished motor gasoline\n",
    "distfuel_prod = 1497761  # Distillate Fuel Oil\n",
    "jetfuel_prod = 636335  # Kerosene-Type Jet Fuel\n",
    "residfuel_prod = 76104  # Residual fuel oil\n",
    "lpg_prod = 1104945  # liquefied petroleum gases\n",
    "other_prod = 6656043 - gas_prod - distfuel_prod - residfuel_prod - \\\n",
    "    jetfuel_prod - lpg_prod  # Total Crude Oil and Petroleum Products - the above\n",
    "refprod_prod = [gas_prod, distfuel_prod, jetfuel_prod, residfuel_prod, lpg_prod, other_prod]\n",
    "\n",
    "refprod_df = pd.DataFrame({\"refprod\": [\"gas\", \"distfuel\", \"jetfuel\", \"residfuel\", \"lpg\", \"other\"],\n",
    "                           \"prod\": refprod_prod})\n",
    "refprod_df[\"frac\"] = refprod_df[\"prod\"] / refprod_df[\"prod\"].sum()\n",
    "\n",
    "# Consumption data\n",
    "cons_crude_ref = 5201596 * 42  # crude oil input into refineries: https://www.eia.gov/dnav/pet/pet_pnp_inpt_dc_nus_mbbl_a.htm, 'Crude Oil'. Units: thousand barrels * 42 = thousand gallons\n",
    "cons_gas = 19307.7 * 365  # refiner motor gasoline sales volumes: https://www.eia.gov/dnav/pet/pet_cons_refmg_d_nus_VTR_mgalpd_a.htm, units: thousand GALLONS per day * 365 days per year\n",
    "\n",
    "# Distillate & residual fuel oil consumption from EIA's adjusted distillate fuel oil and kerosene sales by end use: https://www.eia.gov/dnav/pet/pet_cons_821usea_dcu_nus_a.htm\n",
    "# units: thousand gallons. Assume all distillate fuel oil used for transport is diesel.\n",
    "cons_dsl_transport = 45086223\n",
    "# units: thousand gallons. Assume all distillate fuel oil used for commercial sector is heating oil.\n",
    "cons_heatoil_comm = 2013097\n",
    "# units: thousand gallons. Assume all distillate fuel oil used for residential sector is heating oil.\n",
    "cons_heatoil_res = 3073435\n",
    "# EIA's 'industrial' + 'Farm' + 'Oil Company' + 'Military' + 'Off-Highway'. units: thousand gallons. Assume all distillate fuel oil used for industrial/agricultural sectors is diesel.\n",
    "cons_dsl_ind = 1471229 + 3630350 + 347185 + 147224 + 2087610\n",
    "cons_dsl_pwr = 338384  # Assume all distillate fuel oil used in power generation is diesel.\n",
    "cons_residfuel_transport = 2625945\n",
    "cons_residfuel_ind = 214449 + 16  # EIA's 'industrial' + 'oil company'\n",
    "cons_residfuel_pwr = 382880  # units: thousand gallons\n",
    "\n",
    "# Other products\n",
    "cons_lpg = lpg_prod + 63175 - 771065  # + imports - exports\n",
    "cons_jetfuel = jetfuel_prod + 54787 - 35296  # + imports - exports\n",
    "# assume consumption of all other products ~ production of said products\n",
    "cons_other = other_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698eb5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that contains the pass-through rates of refined products onto consumers, refineries, and producers for each refined product\n",
    "rho_fuels = fuel_elast[(fuel_elast[\"fuel\"] == \"residfuel\") | (fuel_elast[\"fuel\"] == \"heatoil\") | (fuel_elast[\"fuel\"] == \"dsl\") |\n",
    "                       (fuel_elast[\"fuel\"] == \"crude\") | (fuel_elast[\"fuel\"] == \"jetfuel\") |\n",
    "                       (fuel_elast[\"fuel\"] == \"gas\") | (fuel_elast[\"fuel\"] == \"lpg\")\n",
    "                       ].copy()\n",
    "Id_ref = rho_fuels[(rho_fuels[\"fuel\"] == \"crude\")][\"Id_avg\"].mean()\n",
    "\n",
    "# Calculate the effective passthrough rate on refineries for each refined product as Id_ref*(1-rho_refprod)\n",
    "retail_sectors = [\"ind\", \"transport\", \"res\", \"comm\"]\n",
    "rho_fuels[\"rho_ref_eff_avg\"] = rho_fuels.apply(lambda x: Id_ref * (1-x[\"rho_avg\"]) if x.sector in retail_sectors else np.nan,\n",
    "                                               axis=1)\n",
    "\n",
    "# For power sector, need also to account for the pass-through rate onto the power plant. This will be Id_pwr*(1-rho_elec).\n",
    "# The pass-through rate onto refineries for the residual fuel oil used in power plants is therefore\n",
    "# Id_ref * passthrough rate onto firms upstream of power plant = Id_ref*(1-Id_pwr)*(1-rho_elec)\n",
    "rho_fuels[\"rho_pwr_eff_avg\"] = rho_fuels.apply(lambda x: x.Id_pwr_avg * (1-rho_elec)\n",
    "                                               if x.sector == \"pwr\"\n",
    "                                               else np.nan,\n",
    "                                               axis=1)\n",
    "rho_fuels[\"rho_ref_eff_avg\"] = rho_fuels.apply(lambda x: Id_ref * (1-x.Id_pwr_avg) * (1-rho_elec)\n",
    "                                               if x.sector == \"pwr\"\n",
    "                                               else x.rho_ref_eff_avg,\n",
    "                                               axis=1)\n",
    "\n",
    "# Calculate the effective passthrough rate onto upstream crude oil producers as (1-Id_ref)*(1-rho_refprod)\n",
    "# For power sector, calculation is (1-Id_ref)*(1-Id_pwr)*(1-rho_elec)\n",
    "rho_fuels[\"rho_prod_eff_avg\"] = rho_fuels.apply(lambda x: (1-Id_ref) * (1-x[\"rho_avg\"])\n",
    "                                                if x.sector in retail_sectors\n",
    "                                                else np.nan,\n",
    "                                                axis=1)\n",
    "rho_fuels[\"rho_prod_eff_avg\"] = rho_fuels.apply(lambda x: (1-Id_ref) * (1-x.Id_pwr_avg) * (1-rho_elec)\n",
    "                                                if x.sector == \"pwr\"\n",
    "                                                else x.rho_prod_eff_avg,\n",
    "                                                axis=1)\n",
    "\n",
    "# Check that passthrough rates add to 1\n",
    "rho_fuels[\"check\"] = rho_fuels.apply(lambda x: x[\"rho_ref_eff_avg\"] + x[\"rho_avg\"] + x[\"rho_prod_eff_avg\"]\n",
    "                                     if x.sector != \"pwr\"\n",
    "                                     else rho_elec + x[\"rho_pwr_eff_avg\"] + x[\"rho_ref_eff_avg\"] + x[\"rho_prod_eff_avg\"],\n",
    "                                     axis=1)\n",
    "\n",
    "# Use these passthrough rates to calculate the effective total amounts of US crude oil production for each refined product that sees the full carbon tax\n",
    "taxed_gas_prod = cons_gas * rho_fuels[rho_fuels.fuel == \"gas\"].rho_prod_eff_avg.mean()\n",
    "taxed_dsl_prod_ind = cons_dsl_ind * rho_fuels[(rho_fuels.fuel == \"dsl\") &\n",
    "                                              (rho_fuels.sector == \"ind\")].rho_prod_eff_avg.mean()\n",
    "taxed_dsl_prod_transport = cons_dsl_transport * rho_fuels[(rho_fuels.fuel == \"dsl\") &\n",
    "                                                          (rho_fuels.sector == \"transport\")].rho_prod_eff_avg.mean()\n",
    "taxed_heatoil_prod_res = cons_heatoil_res * rho_fuels[(rho_fuels.fuel == \"heatoil\") &\n",
    "                                                      (rho_fuels.sector == \"res\")].rho_prod_eff_avg.mean()\n",
    "taxed_heatoil_prod_comm = cons_heatoil_comm * rho_fuels[(rho_fuels.fuel == \"heatoil\") &\n",
    "                                                        (rho_fuels.sector == \"comm\")].rho_prod_eff_avg.mean()\n",
    "taxed_residfuel_prod_ind = cons_residfuel_ind * rho_fuels[(rho_fuels.fuel == \"residfuel\") &\n",
    "                                                          (rho_fuels.sector == \"ind\")].rho_prod_eff_avg.mean()\n",
    "taxed_residfuel_prod_transport = cons_residfuel_transport * rho_fuels[(rho_fuels.fuel == \"residfuel\") &\n",
    "                                                                      (rho_fuels.sector == \"transport\")].rho_prod_eff_avg.mean()\n",
    "taxed_residfuel_prod_pwr = cons_residfuel_pwr * rho_fuels[(rho_fuels.fuel == \"residfuel\") &\n",
    "                                                          (rho_fuels.sector == \"pwr\")].rho_prod_eff_avg.mean()\n",
    "taxed_jetfuel_prod = cons_jetfuel * rho_fuels[(rho_fuels.fuel == \"jetfuel\") &\n",
    "                                              (rho_fuels.sector == \"transport\")].rho_prod_eff_avg.mean()\n",
    "taxed_other_prod = cons_other * rho_fuels[(rho_fuels.fuel == \"dsl\") &\n",
    "                                          (rho_fuels.sector == \"ind\")].rho_prod_eff_avg.mean()  # assume passthrough rate for other fuels = that of industrial diesel\n",
    "\n",
    "# Calculate the total effective amount of US crude oil production that sees the full carbon tax, and use this to calculate the effective producer passthrough rate on oil producers.\n",
    "total_taxed_production = (\n",
    "    taxed_gas_prod\n",
    "    + taxed_dsl_prod_ind\n",
    "    + taxed_dsl_prod_transport\n",
    "    + taxed_heatoil_prod_res\n",
    "    + taxed_heatoil_prod_comm\n",
    "    + taxed_residfuel_prod_ind\n",
    "    + taxed_residfuel_prod_transport\n",
    "    + taxed_residfuel_prod_pwr\n",
    "    + taxed_jetfuel_prod\n",
    "    + taxed_other_prod\n",
    ")\n",
    "\n",
    "rho_eff_oil = total_taxed_production / (crude_prod * 42)\n",
    "rho_eff_oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5667ae1-0fde-4bed-98bb-643aaf35869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is useful for the burden calculations below to use the passthrough rates dataframe \n",
    "# above to calculate the total amount of refined product that sees the full carbon tax, \n",
    "# as well as the total amount of product consumption that sees the full carbon tax\n",
    "# Use passthrough rates to calculate the effective total amounts of product refined in\n",
    "#  the US that sees the full carbon tax for each refined product\n",
    "taxed_gas_ref = cons_gas * \\\n",
    "    rho_fuels[rho_fuels.fuel == \"gas\"].rho_ref_eff_avg.mean()\n",
    "taxed_dsl_ref_ind = cons_dsl_ind * \\\n",
    "    rho_fuels[(rho_fuels.fuel == \"dsl\") & (rho_fuels.sector == \"ind\")\n",
    "              ].rho_ref_eff_avg.mean()\n",
    "taxed_dsl_ref_transport = cons_dsl_transport * \\\n",
    "    rho_fuels[(rho_fuels.fuel == \"dsl\") & (rho_fuels.sector == \"transport\")\n",
    "              ].rho_ref_eff_avg.mean()\n",
    "taxed_heatoil_ref_res = cons_heatoil_res * \\\n",
    "    rho_fuels[(rho_fuels.fuel == \"heatoil\") & (rho_fuels.sector == \"res\")\n",
    "              ].rho_ref_eff_avg.mean()\n",
    "taxed_heatoil_ref_comm = cons_heatoil_comm * \\\n",
    "    rho_fuels[(rho_fuels.fuel == \"heatoil\") & (rho_fuels.sector == \"comm\")\n",
    "              ].rho_ref_eff_avg.mean()\n",
    "taxed_residfuel_ref_ind = cons_residfuel_ind * \\\n",
    "    rho_fuels[(rho_fuels.fuel == \"residfuel\") & (rho_fuels.sector == \"ind\")\n",
    "              ].rho_ref_eff_avg.mean()\n",
    "taxed_residfuel_ref_transport = cons_residfuel_transport * \\\n",
    "    rho_fuels[(rho_fuels.fuel == \"residfuel\") & (rho_fuels.sector == \"transport\")\n",
    "              ].rho_ref_eff_avg.mean()\n",
    "taxed_residfuel_ref_pwr = cons_residfuel_pwr * \\\n",
    "    rho_fuels[(rho_fuels.fuel == \"residfuel\") & (rho_fuels.sector == \"pwr\")\n",
    "              ].rho_ref_eff_avg.mean()\n",
    "taxed_jetfuel_ref = cons_jetfuel * \\\n",
    "    rho_fuels[(rho_fuels.fuel == \"jetfuel\")].rho_ref_eff_avg.mean()\n",
    "taxed_other_ref = cons_other * \\\n",
    "    rho_fuels[(rho_fuels.fuel == \"dsl\") & (rho_fuels.sector == \"ind\")\n",
    "              ].rho_ref_eff_avg.mean()  # assume passthrough rate for other fuels = that of industrial diesel\n",
    "\n",
    "#  Calculate the US total amount of refined product produced that sees the full carbon tax\n",
    "total_taxed_refinery = (\n",
    "    taxed_gas_ref\n",
    "    + taxed_dsl_ref_ind\n",
    "    + taxed_dsl_ref_transport\n",
    "    + taxed_heatoil_ref_res\n",
    "    + taxed_heatoil_ref_comm\n",
    "    + taxed_residfuel_ref_ind\n",
    "    + taxed_residfuel_ref_transport\n",
    "    + taxed_residfuel_ref_pwr\n",
    "    + taxed_jetfuel_ref\n",
    "    + taxed_other_ref\n",
    ")\n",
    "\n",
    "# Use passthrough rates to calculate the effective total amounts of product refined in the US that sees the full carbon tax for each refined product\n",
    "taxed_gas_cons = cons_gas * \\\n",
    "    rho_fuels[rho_fuels.fuel == \"gas\"].rho_avg.mean()\n",
    "taxed_dsl_cons_ind = cons_dsl_ind * \\\n",
    "    rho_fuels[(rho_fuels.fuel == \"dsl\") & (rho_fuels.sector == \"ind\")\n",
    "              ].rho_avg.mean()\n",
    "taxed_dsl_cons_transport = cons_dsl_transport * \\\n",
    "    rho_fuels[(rho_fuels.fuel == \"dsl\") & (rho_fuels.sector == \"transport\")\n",
    "              ].rho_avg.mean()\n",
    "taxed_heatoil_cons_res = cons_heatoil_res * \\\n",
    "    rho_fuels[(rho_fuels.fuel == \"heatoil\") & (rho_fuels.sector == \"res\")\n",
    "              ].rho_avg.mean()\n",
    "taxed_heatoil_cons_comm = cons_heatoil_comm * \\\n",
    "    rho_fuels[(rho_fuels.fuel == \"heatoil\") & (rho_fuels.sector == \"comm\")\n",
    "              ].rho_avg.mean()\n",
    "taxed_residfuel_cons_ind = cons_residfuel_ind * \\\n",
    "    rho_fuels[(rho_fuels.fuel == \"residfuel\") & (rho_fuels.sector == \"ind\")\n",
    "              ].rho_avg.mean()\n",
    "taxed_residfuel_cons_transport = cons_residfuel_transport * \\\n",
    "    rho_fuels[(rho_fuels.fuel == \"residfuel\") & (rho_fuels.sector == \"transport\")\n",
    "              ].rho_avg.mean()\n",
    "taxed_residfuel_cons_pwr = cons_residfuel_pwr * rho_elec\n",
    "taxed_jetfuel_cons = cons_jetfuel * \\\n",
    "    rho_fuels[(rho_fuels.fuel == \"jetfuel\")].rho_avg.mean()\n",
    "taxed_other_cons = cons_other * \\\n",
    "    rho_fuels[(rho_fuels.fuel == \"dsl\") & (rho_fuels.sector == \"ind\")\n",
    "              ].rho_avg.mean()  # assume passthrough rate for other fuels = that of industrial diesel\n",
    "\n",
    "#  Calculate the US total amount of refined product produced that sees the full carbon tax\n",
    "total_taxed_cons = (\n",
    "    taxed_gas_cons\n",
    "    + taxed_dsl_cons_ind\n",
    "    + taxed_dsl_cons_transport\n",
    "    + taxed_heatoil_cons_res\n",
    "    + taxed_heatoil_cons_comm\n",
    "    + taxed_residfuel_cons_ind\n",
    "    + taxed_residfuel_cons_transport\n",
    "    + taxed_residfuel_cons_pwr\n",
    "    + taxed_jetfuel_cons\n",
    "    + taxed_other_cons\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3bb0ca-9898-4796-88a9-5f789f389c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group these effective incidences in a dictionary\n",
    "rho_ffprod_eff = {\"coal\": rho_prod_coal_eff, \"ng\": rho_prod_ng_eff, \"crude\": rho_eff_oil}\n",
    "rho_ffprod_eff"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b01b9a6-c106-4a09-8ea2-0b3017430606",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2.3 Define functions to perform calculations necessary to determine burden for a given datapoint\n",
    "These functions calculate the following:\n",
    "1. rho_eff: The effective passthrough rate of a carbon tax to energy consumers/producers for a given fuel and sector in a given county.\n",
    "2. Id_pwr: The portion of firm burden in the electricity supply chain that is borne by the power plant (i.e. the 'downstream retailer' firm).\n",
    "3. burden: The change in consumer/producer surplus resulting from the carbon tax for a given fuel in a given sector, in a given county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2c607d-83ca-4cf9-82e4-1ec99f708e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that isolates all FIPS with NAICS 324 emissions (taken to be oil refining) and\n",
    "# calculates the amount of those emissions that see the full carbon tax\n",
    "#  Read in industrial data\n",
    "taxed_refined_percounty = getIndustrialData(\"mf\", \"agg\", \"totals\").copy()\n",
    "\n",
    "#  Isolate NAICS 324 counties\n",
    "taxed_refined_percounty = taxed_refined_percounty[taxed_refined_percounty[\"NAICS\"] == \"324\"]\n",
    "\n",
    "#  Because we don't have the quantity of refined product produced per county (just the scope 1 and 2\n",
    "#  emissions associated with the refinery process), we need to make an assumption about how much\n",
    "#  product each refinery handles. Assume that the amount of product handled is directly proportional\n",
    "#  to the emissions of the refinery. Therefore, the fraction of total US refined product production\n",
    "#  that each county's refineries are responsible for can be estimated using the fraction of total US\n",
    "#  refinery emissions produced in the county\n",
    "taxed_refined_percounty[\"rel_ref_em_frac\"] = taxed_refined_percounty[\"tonCO2e\"] / taxed_refined_percounty[\"tonCO2e\"].sum()\n",
    "\n",
    "#  Use this fraction to estimate the total amount of refined product (in tonCO2e) that sees the full carbon tax, \n",
    "#  by multiplying the fraction by the US total amount of refined product that sees the full carbon tax (calculated earlier)\n",
    "taxed_refined_percounty[\"tonCO2e_ref\"] = taxed_refined_percounty[\"rel_ref_em_frac\"] * total_taxed_refinery\n",
    "\n",
    "#  Isolate useful columns\n",
    "taxed_refined_percounty = taxed_refined_percounty[[\"FIPS\", \"tonCO2e\", \"tonCO2e_ref\"]]\n",
    "\n",
    "# Write to csv\n",
    "taxed_refined_percounty.to_csv(\"../Temp/taxed_refined_percounty.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee94a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate the effective passthrough rate for a given county-sector-scope-fuel combo.\n",
    "def calc_rho_eff(scope=str, fuel=str, sector_code=str, nerc=str, min_max_avg='avg'):\n",
    "    '''\n",
    "    Calculates the effective passthrough rate of a carbon tax (rho_eff) for consumption\n",
    "    of a given fuel in a given sector and county.\n",
    "\n",
    "    Parameters:\n",
    "        scope (str): Scope of emissions to which the passthrough rate will be applied.\n",
    "            'scope1', 'scope2' or 'scope3'.\n",
    "        fuel (str): Fuel type that emissions are attributable to.\n",
    "        sector_code (str): 'ind', 'comm' or 'pwr'. Encoded value of the sector category\n",
    "            in original sector_scope dataframe.\n",
    "        nerc (str): NERC region for the given county.\n",
    "        min_max_avg (str): One of 'min', 'max', 'avg'. Dictates whether rho_eff returned \n",
    "            is the value calculated using the maximum, minimum or average elasticity \n",
    "            figures used in the excel sheet.\n",
    "\n",
    "    PROCEDURE:\n",
    "    For end-use emissions (e.g. consumption of natural gas in manufacturing, commercial \n",
    "    electricity consumption), the effective passthrough rate is equal to the final \n",
    "    passthrough rate as calculated in fuel_elasticities.xlsx (i.e. rho). This category\n",
    "    includes all Scope 2 emissions as well as Scope 1 emissions that do not occur at a \n",
    "    power plant.\n",
    "\n",
    "    For fossil fuel producers (scope 3 emissions), the effective passthrough rate of a \n",
    "    carbon tax levied on the consumption of the fuels they produce is equal to the\n",
    "    effective passthrough rates calculated in Section 2.1.2.1.\n",
    "\n",
    "    For power generation firms (Scope 1 emissions at power plants), the effective pass-\n",
    "    through rate is equal to Id_pwr*(1-rho_elec), where rho_elec = the passthrough rate \n",
    "    onto consumers for electricity consumption, (1-rho_elec) = the effective passthrough \n",
    "    rate onto firms from electricity consumption, and Id_pwr = the portion of firm \n",
    "    passthrough that is borne by the downstream retailer (in this case, the power plant).\n",
    "\n",
    "    For oil refineries, which purchase crude and produce refined products that are \n",
    "    consumed elsewhere, the effective passthrough rate onto refineries is equal to \n",
    "    Id_ref*(1-rho_refprod), where rho_refprod = the passthrough rate onto consumers for \n",
    "    a given refined product, (1-rho_refprod) = the effective passthrough rate onto firms \n",
    "    from consumption of said refined product, and Id_ref = the portion of firm pass-\n",
    "    through that is borne by the downstream retailed (in this case, the oil refinery). \n",
    "    The EXCEPTION to this rule is the case of refined product (residual fuel oil) being \n",
    "    used in power generation, as this introduces an additional layer to the supply chain. \n",
    "    In this case, the effective passthrough rate onto refineries \n",
    "    = Id_ref*(1-Id_pwr)*(1-rho_elec), where (1-Id_pwr) = the effective passthrough rate \n",
    "    from electricity consumption onto firms upstream of the power plant.\n",
    "    '''\n",
    "    # Start with scope 3 emissions from fossil fuel production. Use effective passthrough rates derived earlier.\n",
    "    if scope == \"scope3\":\n",
    "        #  Use effective passthrough rates derived earlier\n",
    "        rho_eff_avg = rho_ffprod_eff[fuel]\n",
    "        rho_eff_min, rho_eff_max = rho_eff_avg, rho_eff_avg\n",
    "\n",
    "    # Next, consider scope 1 emissions in the commercial and industrial (including fossil fuel extraction) sectors (NOT POWER GENERATION)\n",
    "    elif scope == \"scope1\" and (sector_code == \"ind\" or sector_code == \"comm\"):\n",
    "        #  Define minimum, maximum and average passthrough rate dictionaries for each fuel type for the given sector\n",
    "        passthroughs_scope1 = fuel_elast[(fuel_elast[\"sector\"] == sector_code) &\n",
    "                                         (fuel_elast[\"fuel\"] == fuel)].copy()\n",
    "        rho_eff_min = passthroughs_scope1[\"rho_min\"].mean()\n",
    "        rho_eff_max = passthroughs_scope1[\"rho_max\"].mean()\n",
    "        rho_eff_avg = passthroughs_scope1[\"rho_avg\"].mean()\n",
    "\n",
    "    # At this point, can read in the passthrough rates for  electricity, as they will be used either in the pwr sector scope 1 calculation or the scope 2 calculations.\n",
    "    else:\n",
    "        #  Read in passthrough rates for electricity\n",
    "        passthroughs_elec = fuel_elast[fuel_elast[\"fuel\"] == \"elec\"].copy()\n",
    "\n",
    "        # Next, consider scope 1 emissions from power sector\n",
    "        if scope == \"scope1\" and sector_code == \"pwr\":\n",
    "            # Extract passthrough rate for electricity consumption across all sectors, for the given NERC region.\n",
    "            rho_elec_ovr_avg = passthroughs_elec[(passthroughs_elec[\"sector\"]\n",
    "                                                 == \"all\") &\n",
    "                                                 (passthroughs_elec[\"nerc\"]\n",
    "                                                  == nerc)][\"rho_avg\"].mean()\n",
    "            rho_elec_ovr_min = passthroughs_elec[(passthroughs_elec[\"sector\"]\n",
    "                                                 == \"all\") &\n",
    "                                                 (passthroughs_elec[\"nerc\"]\n",
    "                                                  == nerc)][\"rho_min\"].mean()\n",
    "            rho_elec_ovr_max = passthroughs_elec[(passthroughs_elec[\"sector\"]\n",
    "                                                 == \"all\") &\n",
    "                                                 (passthroughs_elec[\"nerc\"]\n",
    "                                                  == nerc)][\"rho_max\"].mean()\n",
    "\n",
    "            # Use calc_Id_pwr function to calculate the max, min and avg Id_pwr values\n",
    "            Id_pwr_min = calc_Id_pwr(fuel=fuel, nerc=nerc, min_max_avg='min')\n",
    "            Id_pwr_max = calc_Id_pwr(fuel=fuel, nerc=nerc, min_max_avg='max')\n",
    "            Id_pwr_avg = calc_Id_pwr(fuel=fuel, nerc=nerc, min_max_avg='avg')\n",
    "\n",
    "            # Calculate effective passthrough rate as Id_pwr*(1-rho_elec)\n",
    "            rho_eff_min = Id_pwr_min * (1-rho_elec_ovr_max)\n",
    "            rho_eff_max = Id_pwr_max * (1-rho_elec_ovr_min)\n",
    "            rho_eff_avg = Id_pwr_avg * (1-rho_elec_ovr_avg)\n",
    "\n",
    "        # Finally, consider scope 2 emissions from electricity generation.\n",
    "        elif scope == \"scope2\":\n",
    "            # Calculate effective passthrough rate as rho_elec\n",
    "            rho_eff_avg = passthroughs_elec[(passthroughs_elec[\"sector\"]\n",
    "                                            == sector_code) &\n",
    "                                            (passthroughs_elec[\"nerc\"]\n",
    "                                            == nerc)][\"rho_avg\"].mean()\n",
    "            rho_eff_min = passthroughs_elec[(passthroughs_elec[\"sector\"]\n",
    "                                            == sector_code) &\n",
    "                                            (passthroughs_elec[\"nerc\"]\n",
    "                                            == nerc)][\"rho_min\"].mean()\n",
    "            rho_eff_max = passthroughs_elec[(passthroughs_elec[\"sector\"]\n",
    "                                            == sector_code) &\n",
    "                                            (passthroughs_elec[\"nerc\"]\n",
    "                                            == nerc)][\"rho_max\"].mean()\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Error: sector not found??\")\n",
    "\n",
    "    if min_max_avg == 'avg':\n",
    "        return rho_eff_avg\n",
    "    elif min_max_avg == 'min':\n",
    "        return rho_eff_min\n",
    "    else:\n",
    "        return rho_eff_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e8a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to extract the portion of total firm burden that is borne by power plants\n",
    "def calc_Id_pwr(fuel=str, nerc=str, min_max_avg='avg'):\n",
    "    '''\n",
    "    Returns Id_pwr, the portion of total firm burden from electricity generation that is \n",
    "    borne by power plants, given a generation fuel type and NERC region.\n",
    "    \n",
    "    Parameters:\n",
    "        fuel (str): One of 'coal', 'ng', 'residfuel'. Fuel type used for power generation.\n",
    "        nerc (str): NERC region for the county in question.\n",
    "        min_max_avg (str): One of 'min', 'max', 'avg'. Dictates whether Id_pwr returned \n",
    "            is the value calculated using the maximum, minimum or average elasticity \n",
    "            figures used in the excel sheet.\n",
    "    '''\n",
    "\n",
    "    Id_pwr_min = fuel_elast[(fuel_elast.sector == 'pwr') &\n",
    "                            (fuel_elast.fuel == fuel) &\n",
    "                            (fuel_elast.nerc == nerc)]['Id_pwr_min'].mean()\n",
    "    Id_pwr_max = fuel_elast[(fuel_elast.sector == 'pwr') &\n",
    "                            (fuel_elast.fuel == fuel) &\n",
    "                            (fuel_elast.nerc == nerc)]['Id_pwr_max'].mean()\n",
    "    Id_pwr_avg = fuel_elast[(fuel_elast.sector == 'pwr') &\n",
    "                            (fuel_elast.fuel == fuel) &\n",
    "                            (fuel_elast.nerc == nerc)]['Id_pwr_avg'].mean()\n",
    "    if min_max_avg == 'avg':\n",
    "        return Id_pwr_avg\n",
    "    elif min_max_avg == 'min':\n",
    "        return Id_pwr_min\n",
    "    else:\n",
    "        return Id_pwr_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558aaa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate burden tax burden for the emissions from consumption/production of a given fuel\n",
    "def calc_burden(rho_eff, SCC, Q):\n",
    "    '''\n",
    "    Calculates the social cost of the consumption/production of a given energy product as \n",
    "    SCC*Q0.\n",
    "\n",
    "    Parameters:\n",
    "        rho_eff (float): Effective passthrough rate of social cost, for fuel and \n",
    "            sector in question.\n",
    "        SCC (float or int): Social cost of carbon in $/short tonCO2e.\n",
    "        Q (float or int): Quantity of emissions in tonCO2e.\n",
    "\n",
    "    PROCEDURE:\n",
    "    The final social cost burden for a given energy product is calculated using the effective \n",
    "    passthrough rate of each energy product (rho_eff), the SCC, and the initial \n",
    "    emissions from that energy product (Q).\n",
    "    '''\n",
    "    cost = rho_eff * SCC * Q\n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b614384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that calculates the tax burden borne by oil refineries from the consumption of refined products.\n",
    "def calc_ref_burden(tax, sector=str, fuel=str, fips=str, scope=str, return_tonCO2e_eff=False):\n",
    "    '''\n",
    "    Calculate the tax burden borne by oil refineries resulting from the downstream \n",
    "    consumption of refined products. Uses the dataframe taxed_refined_percounty,\n",
    "    containing the equivalent amount of emissions (in tonCO2e) produced during the \n",
    "    consumption of refined products that is borne by refineries in each county. This\n",
    "    amount is equivalent to the total amount of refined product in tonCO2e that\n",
    "    'sees' the full carbon tax. Therefore, the burden borne by oil refineries is \n",
    "    equal to this quantity * the tax rate.\n",
    "    Also gives the option to return the equivalent amount of emissions if requested.\n",
    "\n",
    "    Parameters:\n",
    "        sector (str): Sector in question (note: unencoded version of sector_code).\n",
    "        fips (str): County FIPS code in question.\n",
    "        scope (str): Scope of emissions in question.\n",
    "        return_tonCO2e_eff (bool, default False): Returns the tonCO2e figure if \n",
    "            True, otherwise proceeds with burden calculation.\n",
    "    '''\n",
    "    # Because we are calculating burden differently for refineries than other sectors,\n",
    "    # we will allocate burden_ref its own column when this function is applied. However,\n",
    "    # because the dataframe these functions will be applied to is in a melted format\n",
    "    # indexed by FIPS, sector, scope, and fuel, just applying this function to each datapoint\n",
    "    # representing an oil-refining county would result in double counting, with the calculation\n",
    "    # being repeated for every sector, every scope within that sector, and every fuel within\n",
    "    # that scope. Therefore, need to attribute this refinery burden to a certain sector-\n",
    "    # scope-fuel combo.\n",
    "\n",
    "    # We will attribute the refinery burden for an oil-refining county to the datapoint\n",
    "    # representing the scope 1 emissions arising from consumption of diesel in the manufacturing\n",
    "    # sector for the given county.\n",
    "\n",
    "    # Check that datapoint in question is an oil-refining county, is considering scope 1 emissions, is considering diesel fuel, and is considering the manufacturing sector.\n",
    "    if all([fips in taxed_refined_percounty[\"FIPS\"].unique(),\n",
    "            scope == 'scope1',\n",
    "            fuel == 'dsl',\n",
    "            sector == 'mf']):\n",
    "        #  Reference the earlier dataframe to find, for a given county, the total amount of refined product (in tonCO2e) that sees the full carbon tax, and calculate tax burden on refinery from consumption of refined products.\n",
    "        if return_tonCO2e_eff == True:\n",
    "            return taxed_refined_percounty[taxed_refined_percounty[\"FIPS\"]\n",
    "                                             == fips][\"tonCO2e_ref\"].mean()\n",
    "        else:\n",
    "            burden_ref = taxed_refined_percounty[taxed_refined_percounty[\"FIPS\"]\n",
    "                                             == fips][\"tonCO2e_ref\"].mean() * tax\n",
    "            return burden_ref\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cdc36558",
   "metadata": {},
   "source": [
    "### 2.2.4 Create final dataframe to perform burden calculations on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1defbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge NERC regions onto master dataframe\n",
    "sector_scope_fuel = pd.merge(sector_scope, fips_nerc_crosswalk,\n",
    "                             how=\"left\", on=\"FIPS\").rename(columns={\"NERC Region\": \"NERC\"})\n",
    "\n",
    "# Drop total emissions and emissions per capita. We will recalculate these after burden calculation.\n",
    "sector_scope_fuel = sector_scope_fuel.drop(columns=['tonCO2e'])\n",
    "\n",
    "# Identify variables to group dataframe by\n",
    "id_vars = ['FIPS', 'County', 'FIPSTATE', 'State', 'NERC', 'sector', 'scope', 'Emp']\n",
    "\n",
    "# Rename columns so that the column name is just the fueltype rather than tonCO2e_fueltype\n",
    "old_col_names = [col for col in sector_scope_fuel.columns if col not in id_vars]\n",
    "new_col_names = [old_col_name[8:] for old_col_name in old_col_names]\n",
    "sector_scope_fuel = sector_scope_fuel.rename(columns=dict(zip(old_col_names, new_col_names)))\n",
    "\n",
    "# Melt dataframe to narrow format, indexed by sector, scope and fuel\n",
    "sector_scope_fuel = pd.melt(frame=sector_scope_fuel,\n",
    "                            id_vars=id_vars,\n",
    "                            value_vars=new_col_names,\n",
    "                            var_name='fuel',\n",
    "                            value_name='tonCO2e')\n",
    "\n",
    "# Drop entries where the emissions associated with a given fuel are 0\n",
    "sector_scope_fuel = sector_scope_fuel[sector_scope_fuel.tonCO2e > 0].reset_index(drop=True)\n",
    "\n",
    "sector_scope_fuel.to_csv('../Temp/sector_scope_fuel.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6bfe649",
   "metadata": {},
   "source": [
    "### 2.2.5 Perform burden calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c666519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the tax that you want to use\n",
    "SCC_dict = {'SCC1': 120 * 1.10231, 'SCC2': 190 * 1.10231, 'SCC3': 340 * 1.10231}  # $/short ton = $ /metric tonne * 1.10231 short tons / metric ton\n",
    "SCC = SCC_dict['SCC2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1784a563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sector_scope_fuel_burdens = sector_scope_fuel_burdens[sector_scope_fuel_burdens.FIPS == '06037'].copy()\n",
    "sector_scope_fuel_burdens = sector_scope_fuel.copy()\n",
    "\n",
    "# First, create column containing sector_code (needed for some of the functions)\n",
    "sector_scope_fuel_burdens['sector_code'] = sector_scope_fuel_burdens.apply(\n",
    "    lambda x: 'ind' if x.sector in [\"ag\", \"cn\", \"mf\", \"mn_rest\", \"coal\", \"og\"] else x.sector, axis=1)\n",
    "\n",
    "# Next, calculate the refinery burden for each oil-refining county\n",
    "sector_scope_fuel_burdens['burden_ref'] = sector_scope_fuel_burdens.apply(lambda x: calc_ref_burden(\n",
    "    tax=SCC, fuel=x.fuel, fips=x.FIPS, sector=x.sector, scope=x.scope), axis=1)\n",
    "\n",
    "# Calculate the minimum, maximum, and average passthrough rate for each datapoint.\n",
    "for min_max_avg in ['min', 'max', 'avg']:\n",
    "    sector_scope_fuel_burdens[f'rho_eff_{min_max_avg}'] = sector_scope_fuel_burdens.apply(\n",
    "        lambda x: calc_rho_eff(scope=x.scope,\n",
    "                               fuel=x.fuel,\n",
    "                               sector_code=x.sector_code,\n",
    "                               nerc=x.NERC,\n",
    "                               min_max_avg=min_max_avg),\n",
    "        axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0168ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the minimum, maximum, and average burden for each datapoint. Add burden_ref to this calculation, then drop burden_ref\n",
    "sector_scope_fuel_burdens['burden_min'] = calc_burden(rho_eff=sector_scope_fuel_burdens.rho_eff_min,\n",
    "                                                      SCC=SCC,\n",
    "                                                      Q=sector_scope_fuel_burdens.tonCO2e,\n",
    "                                                      ) + sector_scope_fuel_burdens.burden_ref\n",
    "sector_scope_fuel_burdens['burden_max'] = calc_burden(rho_eff=sector_scope_fuel_burdens.rho_eff_max,\n",
    "                                                      SCC=SCC,\n",
    "                                                      Q=sector_scope_fuel_burdens.tonCO2e,\n",
    "                                                      ) + sector_scope_fuel_burdens.burden_ref\n",
    "sector_scope_fuel_burdens['burden_avg'] = calc_burden(rho_eff=sector_scope_fuel_burdens.rho_eff_avg,\n",
    "                                                      SCC=SCC,\n",
    "                                                      Q=sector_scope_fuel_burdens.tonCO2e,\n",
    "                                                      ) + sector_scope_fuel_burdens.burden_ref\n",
    "\n",
    "sector_scope_fuel_burdens = sector_scope_fuel_burdens.drop(columns='burden_ref')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd16600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate minimum, maximum and average *effective* emissions for that datapoint, as the effective passthrough rate * the actual emissions.\n",
    "for min_max_avg in ['min', 'max', 'avg']:\n",
    "    # Also add the tonCO2e_eff from refineries\n",
    "    sector_scope_fuel_burdens[f'tonCO2e_eff_{min_max_avg}'] = sector_scope_fuel_burdens.apply(\n",
    "        lambda x: x[f'rho_eff_{min_max_avg}'] * x['tonCO2e'] + calc_ref_burden(tax=SCC_dict['SCC2'],\n",
    "                                                                               fips=x.FIPS,\n",
    "                                                                               sector=x.sector,\n",
    "                                                                               scope=x.scope,\n",
    "                                                                               return_tonCO2e_eff=True),\n",
    "        axis=1)\n",
    "\n",
    "# Create new columns that only keeps the emission/burden values of the row if there is no missing data (i.e. nans) in the Emp field. These columns will be the ones used to compute tonCO2e_peremp/burden_peremp\n",
    "for min_max_avg in ['min', 'max', 'avg']:\n",
    "    sector_scope_fuel_burdens[f'tonCO2e_eff_{min_max_avg}_emp'] = sector_scope_fuel_burdens.apply(\n",
    "        lambda x: x[f'tonCO2e_eff_{min_max_avg}'] if x.Emp > 0 else np.nan,\n",
    "        axis=1)\n",
    "    sector_scope_fuel_burdens[f'burden_{min_max_avg}_emp'] = sector_scope_fuel_burdens.apply(\n",
    "        lambda x: x[f'burden_{min_max_avg}'] if x.Emp > 0 else np.nan,\n",
    "        axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309a7883",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('No. counties covered before calculating burden:', sector_scope_fuel.FIPS.nunique())\n",
    "print('No. counties covered after calculating burden:', sector_scope_fuel_burdens.FIPS.nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "242026b7",
   "metadata": {},
   "source": [
    "## 2.3 Finalize sector-scope, sector, scope, and total dataframes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c601b9d8",
   "metadata": {},
   "source": [
    "### 2.3.1 Aggregate to get sector-scope emissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffa1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create aggregated dataframe, aggregating across fuels\n",
    "groupby_cols = ['FIPS', 'County', 'FIPSTATE', 'State', 'NERC', 'sector', 'scope', 'Emp']\n",
    "\n",
    "final_sector_scope = sector_scope_fuel_burdens.groupby(by=groupby_cols,\n",
    "                                                       as_index=False,\n",
    "                                                       dropna=False).sum(numeric_only=True)\n",
    "\n",
    "# Overwrite effective passthrough rate columns (as they have now been aggregated), and calculate effective tax rate\n",
    "for min_max_avg in ['min', 'max', 'avg']:\n",
    "    final_sector_scope[f'rho_eff_{min_max_avg}'] = final_sector_scope[f'tonCO2e_eff_{min_max_avg}'] / \\\n",
    "        final_sector_scope['tonCO2e']\n",
    "    # final_sector_scope[f'tax_eff_{min_max_avg}'] = final_sector_scope[f'rho_eff_{min_max_avg}'] * CO2tax\n",
    "\n",
    "# Run CensusBureauPopEstimates.ipynb to define function get_pop_estimate() needed to extract Census Population Estimates for a given year data\n",
    "%run ../../../Data/empData/Scripts/CensusBureauPopEstimates.ipynb\n",
    "\n",
    "# Use get_pop_estimate() function to extract 2018 population estimates for each county\n",
    "county_pop_2018 = get_pop_estimate(2018, \"county\")\n",
    "county_pop_2018[\"FIPS\"] = county_pop_2018[\"state\"] + county_pop_2018[\"county\"]\n",
    "\n",
    "# Merge population onto final_sector_scope\n",
    "final_sector_scope = pd.merge(final_sector_scope, county_pop_2018[[\"FIPS\", \"POP\"]], \n",
    "                              how=\"left\", \n",
    "                              on=\"FIPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721da0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the log10 values, and per employee values for tonCO2e. Use *effective* tonCO2e values in order to avoid double counting.\n",
    "for min_max_avg in ['min', 'max', 'avg']:\n",
    "    # Calculate log10 of absolute effective carbon emissions\n",
    "    final_sector_scope[f'tonCO2e_eff_{min_max_avg}_log10'] = np.log10(\n",
    "        final_sector_scope[f'tonCO2e_eff_{min_max_avg}'])\n",
    "\n",
    "    # Calculate per capita effective carbon emissions (in both tonsCO2e and lbCO2e), then calculate log10 value\n",
    "    final_sector_scope[f'tonCO2e_eff_percapita_{min_max_avg}'] = final_sector_scope.apply(\n",
    "        lambda x: x[f'tonCO2e_eff_{min_max_avg}'] / x.POP\n",
    "        if x[f'tonCO2e_eff_{min_max_avg}'] > 0 else np.nan,\n",
    "        axis=1)\n",
    "    final_sector_scope[f'tonCO2e_eff_percapita_{min_max_avg}_log10'] = np.log10(\n",
    "        final_sector_scope[f\"tonCO2e_eff_percapita_{min_max_avg}\"])\n",
    "    final_sector_scope[f'lbCO2e_eff_percapita_{min_max_avg}'] = final_sector_scope[f'tonCO2e_eff_percapita_{min_max_avg}'] * 2000\n",
    "    final_sector_scope[f'lbCO2e_eff_percapita_{min_max_avg}_log10'] = np.log10(\n",
    "        final_sector_scope[f\"lbCO2e_eff_percapita_{min_max_avg}\"])\n",
    "\n",
    "    # Calculate per employee effective carbon emissions, then calculate log10 value\n",
    "    final_sector_scope[f'tonCO2e_eff_peremp_{min_max_avg}'] = final_sector_scope[f'tonCO2e_eff_{min_max_avg}_emp'] / \\\n",
    "        final_sector_scope.Emp\n",
    "    final_sector_scope[f'tonCO2e_eff_peremp_{min_max_avg}_log10'] = np.log10(\n",
    "        final_sector_scope[f\"tonCO2e_eff_peremp_{min_max_avg}\"])\n",
    "\n",
    "    # Calculate log10 of absolute burden\n",
    "    final_sector_scope[f\"burden_{min_max_avg}_log10\"] = np.log10(\n",
    "        final_sector_scope[f\"burden_{min_max_avg}\"])\n",
    "\n",
    "    # Calculate per capita burden, then calculate log10 value\n",
    "    final_sector_scope[f\"burden_percapita_{min_max_avg}\"] = final_sector_scope.apply(\n",
    "        lambda x: x[f\"burden_{min_max_avg}\"] / x.POP\n",
    "        if x[f'burden_{min_max_avg}'] > 0 else np.nan,\n",
    "        axis=1)\n",
    "    final_sector_scope[f\"burden_percapita_{min_max_avg}_log10\"] = np.log10(\n",
    "        final_sector_scope[f\"burden_percapita_{min_max_avg}\"])\n",
    "\n",
    "    # Calculate per employee burden, then calculate log10 value\n",
    "    final_sector_scope[f\"burden_peremp_{min_max_avg}\"] = final_sector_scope.apply(\n",
    "        lambda x: x[f'burden_{min_max_avg}'] / x.Emp\n",
    "        if x.Emp > 0 else np.nan,\n",
    "        axis=1)\n",
    "    final_sector_scope[f\"burden_peremp_{min_max_avg}_log10\"] = np.log10(\n",
    "        final_sector_scope[f'burden_peremp_{min_max_avg}'])\n",
    "\n",
    "final_sector_scope.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2594c899",
   "metadata": {},
   "source": [
    "### 2.3.2 Aggregate to get sectoral emissions/burdens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d2c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group final_sector_scope by sector for each county (i.e. summing across scopes).\n",
    "# Note that should only be dealing with *effective* emissions at this point to avoid double counting\n",
    "groupby_cols = ['FIPS', 'County', 'FIPSTATE', 'State', 'NERC', 'sector', 'Emp', 'POP']\n",
    "final_sector = final_sector_scope.groupby(by=groupby_cols,\n",
    "                                          as_index=False,\n",
    "                                          dropna=False).sum(numeric_only=True)\n",
    "\n",
    "# Overwrite effective passthrough rate columns (as they have now been aggregated), and calculate effective tax rate\n",
    "for min_max_avg in ['min', 'max', 'avg']:\n",
    "    final_sector[f'rho_eff_{min_max_avg}'] = final_sector[f'tonCO2e_eff_{min_max_avg}'] / \\\n",
    "        final_sector['tonCO2e']\n",
    "    # final_sector[f'tax_eff_{min_max_avg}'] = final_sector[f'rho_eff_{min_max_avg}'] * CO2tax\n",
    "\n",
    "# Drop 'tonCO2e' (which will have double-counted emissions during the grouping) to avoid confusion with tonCO2e_eff\n",
    "final_sector = final_sector.drop(columns='tonCO2e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc05a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the log10 values, and per employee values for tonCO2e. Use *effective* tonCO2e values in order to avoid double counting.\n",
    "for min_max_avg in ['min', 'max', 'avg']:\n",
    "    # Calculate log10 of absolute effective carbon emissions\n",
    "    final_sector[f'tonCO2e_eff_{min_max_avg}_log10'] = np.log10(\n",
    "        final_sector[f'tonCO2e_eff_{min_max_avg}'])\n",
    "\n",
    "    # Calculate per capita effective carbon emissions, then calculate log10 value\n",
    "    final_sector[f'tonCO2e_eff_percapita_{min_max_avg}'] = final_sector.apply(\n",
    "        lambda x: x[f'tonCO2e_eff_{min_max_avg}'] / x.POP\n",
    "        if x[f'tonCO2e_eff_{min_max_avg}'] > 0 else np.nan,\n",
    "        axis=1)\n",
    "    final_sector[f'tonCO2e_eff_percapita_{min_max_avg}_log10'] = np.log10(\n",
    "        final_sector[f\"tonCO2e_eff_percapita_{min_max_avg}\"])\n",
    "    final_sector[f'lbCO2e_eff_percapita_{min_max_avg}'] = final_sector[f'tonCO2e_eff_percapita_{min_max_avg}'] * 2000\n",
    "    final_sector[f'lbCO2e_eff_percapita_{min_max_avg}_log10'] = np.log10(final_sector[f\"lbCO2e_eff_percapita_{min_max_avg}\"])\n",
    "\n",
    "    # Calculate per employee effective carbon emissions, then calculate log10 value\n",
    "    final_sector[f'tonCO2e_eff_peremp_{min_max_avg}'] = final_sector[f'tonCO2e_eff_{min_max_avg}_emp'] / \\\n",
    "        final_sector.Emp\n",
    "    final_sector[f'tonCO2e_eff_peremp_{min_max_avg}_log10'] = np.log10(\n",
    "        final_sector[f\"tonCO2e_eff_peremp_{min_max_avg}\"])\n",
    "\n",
    "    # Calculate log10 of absolute burden\n",
    "    final_sector[f\"burden_{min_max_avg}_log10\"] = np.log10(final_sector[f\"burden_{min_max_avg}\"])\n",
    "\n",
    "    # Calculate per capita burden, then calculate log10 value\n",
    "    final_sector[f\"burden_percapita_{min_max_avg}\"] = final_sector.apply(\n",
    "        lambda x: x[f\"burden_{min_max_avg}\"] / x.POP\n",
    "        if x[f'burden_{min_max_avg}'] > 0 else np.nan,\n",
    "        axis=1)\n",
    "    final_sector[f\"burden_percapita_{min_max_avg}_log10\"] = np.log10(\n",
    "        final_sector[f\"burden_percapita_{min_max_avg}\"])\n",
    "\n",
    "    # Calculate per employee burden, then calculate log10 value\n",
    "    final_sector[f\"burden_peremp_{min_max_avg}\"] = final_sector.apply(\n",
    "        lambda x: x[f'burden_{min_max_avg}'] / x.Emp\n",
    "        if x.Emp > 0 else np.nan,\n",
    "        axis=1)\n",
    "    final_sector[f\"burden_peremp_{min_max_avg}_log10\"] = np.log10(\n",
    "        final_sector[f'burden_peremp_{min_max_avg}'])\n",
    "\n",
    "final_sector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ce5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sectoral employment per county for use in construction of future dataframes\n",
    "sectoral_emp = final_sector[[\"FIPS\", \"sector\", \"Emp\"]].drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6454785f",
   "metadata": {},
   "source": [
    "### 2.3.3 Aggregate to get scope emissions/burdens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2bbd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group final_sector_scope by scope for each county (i.e. sum across sectors)\n",
    "# Note that should only be dealing with *effective* emissions at this point to avoid double counting.\n",
    "groupby_cols = ['FIPS', 'County', 'FIPSTATE', 'State', 'NERC', 'scope', 'POP']\n",
    "final_scope = final_sector_scope.groupby(by=groupby_cols,\n",
    "                                         as_index=False,\n",
    "                                         dropna=False).sum(numeric_only=True)\n",
    "\n",
    "# Merge total county employment onto dataframe, as currently the 'Emp' field only contains employment in sectors that have emissions of a given scope,\n",
    "# meaning that all scope 3 datapoints only record employment for those working in fossil fuel extraction, not total county employment\n",
    "final_scope = pd.merge(\n",
    "    final_scope.drop(columns='Emp'),\n",
    "    total_county_emp_lehd,\n",
    "    how='left',\n",
    "    on='FIPS'\n",
    ")\n",
    "\n",
    "# Overwrite effective passthrough rate columns (as they have now been aggregated), and calculate effective tax rate.\n",
    "for min_max_avg in ['min', 'max', 'avg']:\n",
    "    final_scope[f'rho_eff_{min_max_avg}'] = final_scope[f'tonCO2e_eff_{min_max_avg}'] / \\\n",
    "        final_scope['tonCO2e']\n",
    "\n",
    "final_scope.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374397aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the log10 values, and per employee values for tonCO2e. Use *effective* tonCO2e values in order to avoid double counting.\n",
    "for min_max_avg in ['min', 'max', 'avg']:\n",
    "    # Calculate log10 of absolute effective carbon emissions\n",
    "    final_scope[f'tonCO2e_eff_{min_max_avg}_log10'] = np.log10(\n",
    "        final_scope[f'tonCO2e_eff_{min_max_avg}'])\n",
    "\n",
    "    # Calculate per capita effective carbon emissions, then calculate log10 value\n",
    "    final_scope[f'tonCO2e_eff_percapita_{min_max_avg}'] = final_scope.apply(\n",
    "        lambda x: x[f'tonCO2e_eff_{min_max_avg}'] / x.POP\n",
    "        if x[f'tonCO2e_eff_{min_max_avg}'] > 0 else np.nan,\n",
    "        axis=1)\n",
    "    final_scope[f'tonCO2e_eff_percapita_{min_max_avg}_log10'] = np.log10(\n",
    "        final_scope[f\"tonCO2e_eff_percapita_{min_max_avg}\"])\n",
    "    final_scope[f'lbCO2e_eff_percapita_{min_max_avg}'] = final_scope[f'tonCO2e_eff_percapita_{min_max_avg}'] * 2000\n",
    "    final_scope[f'lbCO2e_eff_percapita_{min_max_avg}_log10'] = np.log10(\n",
    "        final_scope[f\"lbCO2e_eff_percapita_{min_max_avg}\"])\n",
    "\n",
    "    # Calculate per employee effective carbon emissions, then calculate log10 value\n",
    "    # NOTE: _emp value NOT used here, as we are using total county employment on the denominator,\n",
    "    # therefore there should be no datapoints without corresponding Emp values\n",
    "    final_scope[f'tonCO2e_eff_peremp_{min_max_avg}'] = final_scope[f'tonCO2e_eff_{min_max_avg}'] / \\\n",
    "        final_scope.Emp\n",
    "    final_scope[f'tonCO2e_eff_peremp_{min_max_avg}_log10'] = np.log10(\n",
    "        final_scope[f\"tonCO2e_eff_peremp_{min_max_avg}\"])\n",
    "\n",
    "    # Calculate log10 of absolute burden\n",
    "    final_scope[f\"burden_{min_max_avg}_log10\"] = np.log10(final_scope[f\"burden_{min_max_avg}\"])\n",
    "\n",
    "    # Calculate per capita burden, then calculate log10 value\n",
    "    final_scope[f\"burden_percapita_{min_max_avg}\"] = final_scope.apply(\n",
    "        lambda x: x[f\"burden_{min_max_avg}\"] / x.POP\n",
    "        if x[f'burden_{min_max_avg}'] > 0 else np.nan,\n",
    "        axis=1)\n",
    "    final_scope[f\"burden_percapita_{min_max_avg}_log10\"] = np.log10(\n",
    "        final_scope[f\"burden_percapita_{min_max_avg}\"])\n",
    "\n",
    "    # Calculate per employee burden, then calculate log10 value\n",
    "    final_scope[f\"burden_peremp_{min_max_avg}\"] = final_scope.apply(\n",
    "        lambda x: x[f'burden_{min_max_avg}'] / x.Emp\n",
    "        if x.Emp > 0 else np.nan,\n",
    "        axis=1)\n",
    "    final_scope[f\"burden_peremp_{min_max_avg}_log10\"] = np.log10(\n",
    "        final_scope[f'burden_peremp_{min_max_avg}'])\n",
    "\n",
    "final_scope.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16bc92bc",
   "metadata": {},
   "source": [
    "### 2.3.4 Aggregate to get total emissions/burdens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group final_sector_scope by county (i.e. sum across sectors AND scopes)\n",
    "# Note that should only be dealing with *effective* emissions at this point to avoid double counting\n",
    "# Also, should drop and remerge the sectoral employment, as this will also have been double counted in the grouping.\n",
    "groupby_cols = ['FIPS', 'County', 'FIPSTATE', 'State', 'NERC', 'POP']\n",
    "final_total = final_sector_scope.groupby(by=groupby_cols,\n",
    "                                         as_index=False,\n",
    "                                         dropna=False).sum(numeric_only=True).drop(columns='Emp')\n",
    "\n",
    "# Merge covered county employment onto the final dataframe\n",
    "final_total = pd.merge(final_total, total_county_emp_lehd, how='left', on='FIPS')\n",
    "\n",
    "# Overwrite effective passthrough rate columns (as they have now been aggregated), and calculate effective tax rate.\n",
    "for min_max_avg in ['min', 'max', 'avg']:\n",
    "    final_total[f'rho_eff_{min_max_avg}'] = final_total[f'tonCO2e_eff_{min_max_avg}'] / \\\n",
    "        final_total['tonCO2e']\n",
    "    # final_total[f'tax_eff_{min_max_avg}'] = final_total[f'rho_eff_{min_max_avg}'] * CO2tax\n",
    "\n",
    "# Drop 'tonCO2e' (which will have double-counted emissions during the grouping) to avoid confusion with tonCO2e_eff\n",
    "final_total = final_total.drop(columns='tonCO2e')\n",
    "\n",
    "final_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea69071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the log10 values, and per employee values for tonCO2e. Use *effective* tonCO2e values in order to avoid double counting.\n",
    "for min_max_avg in ['min', 'max', 'avg']:\n",
    "    # Calculate log10 of absolute effective carbon emissions\n",
    "    final_total[f'tonCO2e_eff_{min_max_avg}_log10'] = np.log10(\n",
    "        final_total[f'tonCO2e_eff_{min_max_avg}'])\n",
    "\n",
    "    # Calculate per capita effective carbon emissions, then calculate log10 value\n",
    "    final_total[f'tonCO2e_eff_percapita_{min_max_avg}'] = final_total.apply(\n",
    "        lambda x: x[f'tonCO2e_eff_{min_max_avg}'] / x.POP\n",
    "        if x[f'tonCO2e_eff_{min_max_avg}'] > 0 else np.nan,\n",
    "        axis=1)\n",
    "    final_total[f'tonCO2e_eff_percapita_{min_max_avg}_log10'] = np.log10(\n",
    "        final_total[f\"tonCO2e_eff_percapita_{min_max_avg}\"])\n",
    "    final_total[f'lbCO2e_eff_percapita_{min_max_avg}'] = final_total[f'tonCO2e_eff_percapita_{min_max_avg}'] * 2000\n",
    "    final_total[f'lbCO2e_eff_percapita_{min_max_avg}_log10'] = np.log10(final_total[f\"lbCO2e_eff_percapita_{min_max_avg}\"])\n",
    "\n",
    "    # Calculate per employee effective carbon emissions, then calculate log10 value\n",
    "    # NOTE: _emp value NOT used here, as we are using total county employment on the denominator,\n",
    "    # therefore there should be no datapoints without corresponding Emp values\n",
    "    final_total[f'tonCO2e_eff_peremp_{min_max_avg}'] = final_total[f'tonCO2e_eff_{min_max_avg}'] / \\\n",
    "        final_total.Emp\n",
    "    final_total[f'tonCO2e_eff_peremp_{min_max_avg}_log10'] = np.log10(\n",
    "        final_total[f\"tonCO2e_eff_peremp_{min_max_avg}\"])\n",
    "\n",
    "    # Calculate log10 of absolute burden\n",
    "    final_total[f\"burden_{min_max_avg}_log10\"] = np.log10(final_total[f\"burden_{min_max_avg}\"])\n",
    "\n",
    "    # Calculate per capita burden, then calculate log10 value\n",
    "    final_total[f\"burden_percapita_{min_max_avg}\"] = final_total.apply(\n",
    "        lambda x: x[f\"burden_{min_max_avg}\"] / x.POP\n",
    "        if x[f'burden_{min_max_avg}'] > 0 else np.nan,\n",
    "        axis=1)\n",
    "    final_total[f\"burden_percapita_{min_max_avg}_log10\"] = np.log10(\n",
    "        final_total[f\"burden_percapita_{min_max_avg}\"])\n",
    "\n",
    "    # Calculate per employee burden, then calculate log10 value\n",
    "    final_total[f\"burden_peremp_{min_max_avg}\"] = final_total.apply(\n",
    "        lambda x: x[f'burden_{min_max_avg}'] / x.Emp\n",
    "        if x.Emp > 0 else np.nan,\n",
    "        axis=1)\n",
    "    final_total[f\"burden_peremp_{min_max_avg}_log10\"] = np.log10(\n",
    "        final_total[f'burden_peremp_{min_max_avg}'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92010905",
   "metadata": {},
   "source": [
    "### 2.3.5 Derive ECFs for fossil fuel extraction vs non-extractive sectors\n",
    "Use total county employment on denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0dd09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group sectoral dataframe by whether or not the sector is a fossil fuel extraction sector\n",
    "final_sector_extract = final_sector.drop(columns='Emp')\n",
    "final_sector_extract['ff_extract'] = final_sector_extract.apply(\n",
    "    lambda x: 1 if x.sector in ['og', 'coal'] else 0, axis=1\n",
    ")\n",
    "final_sector_extract = final_sector_extract.groupby(\n",
    "    by=['FIPS', 'County', 'FIPSTATE', 'State', 'POP', 'ff_extract'],\n",
    "    as_index=False\n",
    ").sum(numeric_only=True)\n",
    "\n",
    "# Merge overall county employment onto dataframe\n",
    "final_sector_extract = final_sector_extract.merge(\n",
    "    total_county_emp_lehd,\n",
    "    how='left',\n",
    "    on='FIPS'\n",
    ")\n",
    "\n",
    "# Calculate the log10 values, and per employee values for tonCO2e. Use *effective* tonCO2e values in order to avoid double counting.\n",
    "# NOTE: _emp value NOT used here, as we are using total county employment on the denominator,\n",
    "# therefore there should be no datapoints without corresponding Emp values\n",
    "for min_max_avg in ['min', 'max', 'avg']:\n",
    "    # Calculate log10 of absolute effective carbon emissions\n",
    "    final_sector_extract[f'tonCO2e_eff_{min_max_avg}_log10'] = np.log10(\n",
    "        final_sector_extract[f'tonCO2e_eff_{min_max_avg}'])\n",
    "\n",
    "    # Calculate per employee effective carbon emissions, then calculate log10 value\n",
    "    final_sector_extract[f'tonCO2e_eff_peremp_{min_max_avg}'] = final_sector_extract[f'tonCO2e_eff_{min_max_avg}'] / \\\n",
    "        final_sector_extract.Emp\n",
    "    final_sector_extract[f'tonCO2e_eff_peremp_{min_max_avg}_log10'] = np.log10(\n",
    "        final_sector_extract[f\"tonCO2e_eff_peremp_{min_max_avg}\"])\n",
    "\n",
    "    # Calculate log10 of absolute burden\n",
    "    final_sector_extract[f\"burden_{min_max_avg}_log10\"] = np.log10(\n",
    "        final_sector_extract[f\"burden_{min_max_avg}\"])\n",
    "\n",
    "    # Calculate per employee burden, then calculate log10 value\n",
    "    final_sector_extract[f\"burden_peremp_{min_max_avg}\"] = final_sector_extract.apply(\n",
    "        lambda x: x[f'burden_{min_max_avg}'] / x.Emp\n",
    "        if x.Emp > 0 else np.nan,\n",
    "        axis=1)\n",
    "    final_sector_extract[f\"burden_peremp_{min_max_avg}_log10\"] = np.log10(\n",
    "        final_sector_extract[f'burden_peremp_{min_max_avg}'])\n",
    "\n",
    "final_sector_extract = final_sector_extract.drop(columns=['tonCO2e_eff_percapita_min',\n",
    "                                                          'tonCO2e_eff_percapita_min_log10', 'lbCO2e_eff_percapita_min',\n",
    "                                                          'lbCO2e_eff_percapita_min_log10', 'burden_percapita_min', 'burden_percapita_min_log10', 'tonCO2e_eff_percapita_max', 'tonCO2e_eff_percapita_max_log10',\n",
    "                                                          'lbCO2e_eff_percapita_max', 'lbCO2e_eff_percapita_max_log10', 'burden_percapita_max',\n",
    "                                                          'burden_percapita_max_log10', 'tonCO2e_eff_percapita_avg', 'tonCO2e_eff_percapita_avg_log10',\n",
    "                                                          'lbCO2e_eff_percapita_avg', 'lbCO2e_eff_percapita_avg_log10', 'burden_percapita_avg',\n",
    "                                                          'burden_percapita_avg_log10', 'tonCO2e_eff_min_emp', 'burden_min_emp', 'tonCO2e_eff_max_emp',\n",
    "                                                          'burden_max_emp', 'tonCO2e_eff_avg_emp', 'burden_avg_emp',])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e99bc0",
   "metadata": {},
   "source": [
    "## 2.4 Winsorize outliers\n",
    "\n",
    "There are several datapoints that skew the ECF distributions in our data by being several orders of magnitude higher or lower than is reasonable. We will therefore winsorize our ECF and burden per employee fields to the 0.4th and 99.7th percentiles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933b6d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column with metric tonnes\n",
    "final_total['tonneCO2e_eff_peremp_avg'] = final_total.tonCO2e_eff_peremp_avg * 0.9071847\n",
    "final_total['tonneCO2e_eff_avg'] = final_total.tonCO2e_eff_avg * 0.9071847\n",
    "final_total['tonneCO2e_eff_peremp_avg_log10'] = np.log10(final_total.tonneCO2e_eff_peremp_avg)\n",
    "\n",
    "final_sector_scope['tonneCO2e_eff_peremp_avg'] = final_sector_scope.tonCO2e_eff_peremp_avg * 0.9071847\n",
    "final_sector_scope['tonneCO2e_eff_peremp_avg_log10'] = np.log10(final_sector_scope.tonneCO2e_eff_peremp_avg)\n",
    "\n",
    "final_sector['tonneCO2e_eff_peremp_avg'] = final_sector.tonCO2e_eff_peremp_avg * 0.9071847\n",
    "final_sector['tonneCO2e_eff_peremp_avg_log10'] = np.log10(final_sector.tonneCO2e_eff_peremp_avg)\n",
    "\n",
    "final_sector_extract['tonneCO2e_eff_peremp_avg'] = final_sector_extract.tonCO2e_eff_peremp_avg * 0.9071847\n",
    "final_sector_extract['tonneCO2e_eff_peremp_avg_log10'] = np.log10(final_sector_extract.tonneCO2e_eff_peremp_avg)\n",
    "\n",
    "final_scope['tonneCO2e_eff_peremp_avg'] = final_scope.tonCO2e_eff_peremp_avg * 0.9071847\n",
    "final_scope['tonneCO2e_eff_peremp_avg_log10'] = np.log10(final_scope.tonneCO2e_eff_peremp_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce729d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate sectoral ECFs into fossil fuel extraction vs non-extraction sectors\n",
    "final_sector_ffextract = final_sector_extract[final_sector_extract.ff_extract == 1].reset_index(drop=True)\n",
    "final_sector_noextract = final_sector_extract[final_sector_extract.ff_extract == 0].reset_index(drop=True)\n",
    "\n",
    "final_scope1 = final_scope[final_scope.scope == 'scope1'].reset_index(drop=True)\n",
    "final_scope2 = final_scope[final_scope.scope == 'scope2'].reset_index(drop=True)\n",
    "final_scope3 = final_scope[final_scope.scope == 'scope3'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85265a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "limits=[0.004, 0.003]\n",
    "\n",
    "for col in [\n",
    "    'burden_peremp_min',\n",
    "    'burden_peremp_min_log10',\n",
    "    'burden_peremp_max',\n",
    "    'burden_peremp_max_log10',\n",
    "    'burden_peremp_avg',\n",
    "    'burden_peremp_avg_log10',\n",
    "    'tonCO2e_eff_peremp_min',\n",
    "    'tonCO2e_eff_peremp_min_log10',\n",
    "    'tonCO2e_eff_peremp_max',\n",
    "    'tonCO2e_eff_peremp_max_log10',\n",
    "    'tonCO2e_eff_peremp_avg',\n",
    "    'tonCO2e_eff_peremp_avg_log10',\n",
    "    'tonneCO2e_eff_peremp_avg',\n",
    "    'tonneCO2e_eff_peremp_avg_log10'\n",
    "]:\n",
    "    final_total[col] = winsorize(\n",
    "        a=np.array(final_total[col]),\n",
    "        limits=limits\n",
    "    )\n",
    "    final_sector[col] = winsorize(\n",
    "        a=np.array(final_sector[col]),\n",
    "        limits=limits\n",
    "    )\n",
    "    final_sector_ffextract[col] = winsorize(\n",
    "        a=np.array(final_sector_ffextract[col]),\n",
    "        limits=limits\n",
    "    )\n",
    "    final_sector_noextract[col] = winsorize(\n",
    "        a=np.array(final_sector_noextract[col]),\n",
    "        limits=limits\n",
    "    )\n",
    "    \n",
    "    for df in [final_scope1, final_scope2, final_scope3]:\n",
    "        df[col] = winsorize(\n",
    "            a=np.array(df[col]),\n",
    "            limits=limits\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ca64bd2-8d88-469b-a4e0-edae0dae45cb",
   "metadata": {},
   "source": [
    "## 2.5 Write key dataframes to csv files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e74048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate z-scores (for visualization purposes)\n",
    "final_total['ECF_std_dev'] = (final_total['tonneCO2e_eff_peremp_avg_log10'] -\n",
    "                              final_total['tonneCO2e_eff_peremp_avg_log10'].mean()) / np.std(final_total['tonneCO2e_eff_peremp_avg_log10'])\n",
    "final_sector_scope['ECF_std_dev'] = (final_sector_scope['tonneCO2e_eff_peremp_avg_log10'] -\n",
    "                                     final_sector_scope['tonneCO2e_eff_peremp_avg_log10'].mean()) / \\\n",
    "    np.std(final_sector_scope['tonneCO2e_eff_peremp_avg_log10'])\n",
    "\n",
    "final_sector_dfs = dict.fromkeys(final_sector.sector.unique())\n",
    "for sector in final_sector.sector.unique():\n",
    "    final_sector_dfs[sector] = final_sector[final_sector.sector ==\n",
    "                                            sector].reset_index(drop=True)\n",
    "    final_sector_dfs[sector]['ECF_std_dev'] = (final_sector_dfs[sector]['tonneCO2e_eff_peremp_avg_log10'] -\n",
    "                                               final_sector_dfs[sector]['tonneCO2e_eff_peremp_avg_log10'].mean()) / \\\n",
    "        np.std(final_sector_dfs[sector]['tonneCO2e_eff_peremp_avg_log10'])\n",
    "\n",
    "final_sector = pd.concat(final_sector_dfs.values(), ignore_index=True)\n",
    "\n",
    "# for extraction dataframes, we want to share the color scale of the overall ecf plots. Therefore, use final_total means and stds.\n",
    "final_sector_ffextract['ECF_std_dev'] = (final_sector_ffextract['tonneCO2e_eff_peremp_avg_log10'] -\n",
    "                                         final_total['tonneCO2e_eff_peremp_avg_log10'].mean()) / \\\n",
    "    np.std(final_total['tonneCO2e_eff_peremp_avg_log10'])\n",
    "final_sector_noextract['ECF_std_dev'] = (final_sector_noextract['tonneCO2e_eff_peremp_avg_log10'] -\n",
    "                                         final_total['tonneCO2e_eff_peremp_avg_log10'].mean()) / \\\n",
    "    np.std(final_total['tonneCO2e_eff_peremp_avg_log10'])\n",
    "\n",
    "final_scope1['ECF_std_dev'] = (final_scope1['tonneCO2e_eff_peremp_avg_log10'] -\n",
    "                               final_scope1['tonneCO2e_eff_peremp_avg_log10'].mean()) / \\\n",
    "    np.std(final_scope1['tonneCO2e_eff_peremp_avg_log10'])\n",
    "final_scope2['ECF_std_dev'] = (final_scope2['tonneCO2e_eff_peremp_avg_log10'] -\n",
    "                               final_scope2['tonneCO2e_eff_peremp_avg_log10'].mean()) / \\\n",
    "    np.std(final_scope2['tonneCO2e_eff_peremp_avg_log10'])\n",
    "final_scope3['ECF_std_dev'] = (final_scope3['tonneCO2e_eff_peremp_avg_log10'] -\n",
    "                               final_scope3['tonneCO2e_eff_peremp_avg_log10'].mean()) / \\\n",
    "    np.std(final_scope3['tonneCO2e_eff_peremp_avg_log10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f787f62-e340-4aca-b37d-4cc60c917b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final results as csv files\n",
    "final_sector_scope.to_csv(\"../Output/ECF_sector_scope.csv\")\n",
    "final_sector.to_csv(\"../Output/ECF_sector.csv\")\n",
    "final_sector_ffextract.to_csv(\"../Output/ECF_sector_ffextract.csv\")\n",
    "final_sector_noextract.to_csv(\"../Output/ECF_sector_noextract.csv\")\n",
    "final_total.to_csv(\"../Output/ECF_total.csv\")\n",
    "final_scope1.to_csv(\"../Output/ECF_scope1.csv\")\n",
    "final_scope2.to_csv(\"../Output/ECF_scope2.csv\")\n",
    "final_scope3.to_csv(\"../Output/ECF_scope3.csv\")\n",
    "\n",
    "for sector in final_sector_dfs.keys():\n",
    "    final_sector_dfs[sector].to_csv(f'../Temp/ECF_sector_{sector}.csv')\n",
    "    final_sector_dfs[sector][final_sector_dfs[sector].ECF_std_dev.isna()].to_csv(f'../Temp/ECF_sector_{sector}_nans.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f411922",
   "metadata": {},
   "source": [
    "# A1 Summary statistics for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38af834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annual direct CO2 emissions (not including other GHGs) from 2016-2020, from https://cfpub.epa.gov/ghgdata/inventoryexplorer/#iallsectors/allsectors/carbondioxide/select/all (U.S. EPA Greenhouse Gas Inventory Data Explorer)\n",
    "co2_2016_2020 = [5251.758, 5210.958, 5376.657, 5259.144, 4715.691]\n",
    "co2_avg = np.mean(co2_2016_2020)\n",
    "print('Average annual direct CO2 emissions between 2016-2020:', np.round(co2_avg,2), 'million metric tonnes')\n",
    "\n",
    "# Annual direct CO2 emissions (not including other GHGs) from 2016-2020 from transport sector\n",
    "co2_transport_2016_2020 = [1757.638, 1779.977, 1812.761, 1813.755, 1572.034]\n",
    "co2_transport_avg = np.mean(co2_transport_2016_2020)\n",
    "print('Average annual direct CO2 emissions from transportation between 2016-2020:', np.round(co2_transport_avg,2), 'million metric tonnes')\n",
    "print('Average annual direct CO2 emissions excluding transportation between 2016-2020:', np.round(co2_avg - co2_transport_avg,2), 'million metric tonnes')\n",
    "\n",
    "# Annual direct CO2e emissions from fossil fuel combustion from 2016-2020\n",
    "co2_ff_2016_2020 = [4909.609, 4853.299, 4989.308, 4852.330, 4342.659]\n",
    "co2_ff_avg = np.mean(co2_ff_2016_2020)\n",
    "print('Average annual CO2e emissions from fossil fuel combustion between 2016-2020:', np.round(co2_ff_avg, 2), 'million metric tonnes' )\n",
    "print('Average annual CO2e emissions from fossil fuel combustion (excluding transportation) between 2016-2020:', np.round(co2_ff_avg - co2_transport_avg, 2), 'million metric tonnes' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57a0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total covered direct emissions in our data\n",
    "direct_co2_covered = final_scope[final_scope.scope == 'scope1'].tonCO2e.sum() / 1e6 / 1.10231\n",
    "\n",
    "print('Direct CO2 emissions covered by our analysis:', np.round(direct_co2_covered,2), 'million metric tonnes')\n",
    "print('Percent of total direct CO2 emissions covered by our analysis:', np.round(direct_co2_covered/co2_avg * 100,2), '%')\n",
    "print('Percent of total direct CO2 emissions (excluding transport) covered by our analysis:', np.round(direct_co2_covered/(co2_avg - co2_transport_avg) * 100,2), '%')\n",
    "print('Percent of total CO2e emissions from fossil fuel combustion covered by our analysis:', np.round(direct_co2_covered / (co2_ff_avg) * 100,2), '%')\n",
    "print('Percent of total CO2e emissions from fossil fuel combustion (excluding transport) covered by our analysis:', np.round(direct_co2_covered / (co2_ff_avg - co2_transport_avg) * 100,2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaac16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total excluded employees according to QCEW (data taken from 2018)\n",
    "emp_excl = 21084389\n",
    "\n",
    "# Total employment beteen 2016-2020, according to BLS CPS (https://www.bls.gov/cps/tables.htm)\n",
    "emp_total_2016_2020 = [151436, 153337, 155761, 157538, 147795]\n",
    "emp_total_avg = np.mean(emp_total_2016_2020)*1e3\n",
    "\n",
    "# Total employment in the sectors our analysis covers\n",
    "emp_covered_sectors = emp_total_avg - emp_excl\n",
    "\n",
    "# Total employment actually recorded in our analysis\n",
    "emp_actual = final_sector.Emp.sum()\n",
    "\n",
    "print('Averge total employment between 2016-2020:', emp_total_avg/1e6, 'million')\n",
    "print('Percent of total employment between 2016-2020 covered by the sectors we consider:', np.round(emp_covered_sectors/emp_total_avg*100, 2), '%')\n",
    "print('Percent of total employment between 2016-2020 corresponding to actual data in our analysis:', np.round(emp_actual/emp_total_avg*100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb05f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No. counties vs population with higher-than-average ECF\n",
    "df = final_total[final_total.tonCO2e_eff_peremp_avg_log10 > final_total.tonCO2e_eff_peremp_avg_log10.mean()]\n",
    "print('No. counties with above-average ECFs:', len(df))\n",
    "print('Percent of counties with above-average ECFs:', np.round(len(df) / len(final_total) * 100, 2), '%')\n",
    "print('Percent of population with above-average ECFs:', np.round(df.POP.sum() / final_total.POP.sum() * 100,2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60362cd",
   "metadata": {},
   "source": [
    "# A2 Calculations for Tableau figures\n",
    "Tableau maps are color coded by logarithmic standard deviation (i.e. z-scores). Therefore, need to manually compute corresponding ECFs to input into the legend. In all instances, round to 2 significant figures for interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950d93dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ECF_std_dev, burden_std_dev = np.std(final_total.tonneCO2e_eff_peremp_avg_log10), np.std(final_total.burden_peremp_avg_log10)\n",
    "ECF_mean, burden_mean = final_total.tonneCO2e_eff_peremp_avg_log10.mean(), final_total.burden_peremp_avg_log10.mean()\n",
    "print(\"Logarithmic mean:\", ECF_mean, \" Std dev:\", ECF_std_dev, ' ECF at log mean:', 10**ECF_mean, ' Burden at log mean:', 10**burden_mean)\n",
    "print(\"Min ECF:\", 10**final_total.tonneCO2e_eff_peremp_avg_log10.min(), ' Max ECF:', 10**final_total.tonneCO2e_eff_peremp_avg_log10.max())\n",
    "print(\"Min burden:\", 10**final_total.burden_peremp_avg_log10.min(), ' Max burden:', 10**final_total.burden_peremp_avg_log10.max())\n",
    "print('Min z-score:', final_total.ECF_std_dev.min(), 'Max z-score:', final_total.ECF_std_dev.max(),)\n",
    "n = 6\n",
    "step = (4 + 2) / n\n",
    "for i in np.arange(-2,5,step):\n",
    "    ECF_log10_i, burden_log10_i = ECF_mean + ECF_std_dev * i, burden_mean + burden_std_dev * i\n",
    "    ECF_i, burden_i = 10**(ECF_log10_i), 10**(burden_log10_i)\n",
    "    print('Z-score:', i, ' ECF:', ECF_i, ' Burden:', burden_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127489ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create state-level dataframe\n",
    "final_total_state = final_total[['FIPSTATE', 'State', 'tonneCO2e_eff_avg', 'burden_avg', 'POP', 'Emp']].groupby(\n",
    "    by=['FIPSTATE', 'State'], as_index=False).sum(numeric_only=True)\n",
    "final_total_state['tonneCO2e_eff_peremp_avg'] = final_total_state.tonneCO2e_eff_avg / \\\n",
    "    final_total_state.Emp\n",
    "final_total_state['tonneCO2e_eff_peremp_avg_log10'] = np.log10(\n",
    "    final_total_state['tonneCO2e_eff_peremp_avg'])\n",
    "final_total_state['burden_peremp_avg'] = final_total_state.burden_avg / final_total_state.Emp\n",
    "final_total_state['burden_peremp_avg_log10'] = np.log10(final_total_state['burden_peremp_avg'])\n",
    "mean = np.mean(final_total_state.tonneCO2e_eff_peremp_avg_log10)\n",
    "std = np.std(final_total_state.tonneCO2e_eff_peremp_avg_log10)\n",
    "final_total_state['ECF_std_dev'] = final_total_state.apply(\n",
    "    lambda x: (x.tonneCO2e_eff_peremp_avg_log10 - mean) / std, axis=1)\n",
    "final_total_state.to_csv('../Output/ECF_total_state.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268e103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ECF_std_dev, burden_std_dev = np.std(final_total_state.tonneCO2e_eff_peremp_avg_log10), np.std(final_total_state.burden_peremp_avg_log10)\n",
    "ECF_mean, burden_mean = final_total_state.tonneCO2e_eff_peremp_avg_log10.mean(), final_total_state.burden_peremp_avg_log10.mean()\n",
    "print(\"Logarithmic mean:\", ECF_mean, \" Std dev:\", ECF_std_dev, ' ECF at log mean:', 10**ECF_mean, ' Burden at log mean:', 10**burden_mean)\n",
    "print(\"Min ECF:\", 10**final_total_state.tonneCO2e_eff_peremp_avg_log10.min(), ' Max ECF:', 10**final_total_state.tonneCO2e_eff_peremp_avg_log10.max())\n",
    "print(\"Min burden:\", 10**final_total_state.burden_peremp_avg_log10.min(), ' Max burden:', 10**final_total_state.burden_peremp_avg_log10.max())\n",
    "print('Min z-score:', final_total_state.ECF_std_dev.min(), 'Max z-score:', final_total_state.ECF_std_dev.max(),)\n",
    "for i in np.arange(-2,4,1):\n",
    "    ECF_log10_i, burden_log10_i = ECF_mean + ECF_std_dev * i, burden_mean + burden_std_dev * i\n",
    "    ECF_i, burden_i = 10**(ECF_log10_i), 10**(burden_log10_i)\n",
    "    print('Z-score:', i, ' ECF:', ECF_i, ' Burden:', burden_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b1bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_sector_ffextract.copy()\n",
    "ECF_std_dev, burden_std_dev = np.std(final_total.tonneCO2e_eff_peremp_avg_log10), np.std(final_total.burden_peremp_avg_log10)\n",
    "ECF_mean, burden_mean = final_total.tonneCO2e_eff_peremp_avg_log10.mean(), final_total.burden_peremp_avg_log10.mean()\n",
    "print(\"Logarithmic mean:\", ECF_mean, \" Std dev:\", ECF_std_dev, ' ECF at log mean:', 10**ECF_mean, ' Burden at log mean:', 10**burden_mean)\n",
    "print(\"Min Z-score:\", df.ECF_std_dev.min(), ' Max Z-score:', df.ECF_std_dev.max())\n",
    "print(\"Min ECF:\", 10**df.tonneCO2e_eff_peremp_avg_log10.min(), ' Max ECF:', 10**df.tonneCO2e_eff_peremp_avg_log10.max())\n",
    "print(\"Min burden:\", 10**df.burden_peremp_avg_log10.min(), ' Max burden:', 10**df.burden_peremp_avg_log10.max())\n",
    "print('Min z-score:', df.ECF_std_dev.min(), 'Max z-score:', df.ECF_std_dev.max(),)\n",
    "for i in np.arange(-2.709,2.719,2.709/3):\n",
    "    ECF_log10_i, burden_log10_i = ECF_mean + ECF_std_dev * i, burden_mean + burden_std_dev * i\n",
    "    ECF_i, burden_i = 10**(ECF_log10_i), 10**(burden_log10_i)\n",
    "    print('Z-score:', i, ' ECF:', ECF_i, ' Burden:', burden_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef792629",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_sector_noextract.copy()\n",
    "ECF_std_dev, burden_std_dev = np.std(df.tonneCO2e_eff_peremp_avg_log10), np.std(df.burden_peremp_avg_log10)\n",
    "ECF_mean, burden_mean = df.tonneCO2e_eff_peremp_avg_log10.mean(), df.burden_peremp_avg_log10.mean()\n",
    "print(\"Logarithmic mean:\", ECF_mean, \" Std dev:\", ECF_std_dev, ' ECF at log mean:', 10**ECF_mean, ' Burden at log mean:', 10**burden_mean)\n",
    "print(\"Min Z-score:\", df.ECF_std_dev.min(), ' Max Z-score:', df.ECF_std_dev.max())\n",
    "print(\"Min ECF:\", 10**df.tonneCO2e_eff_peremp_avg_log10.min(), ' Max ECF:', 10**df.tonneCO2e_eff_peremp_avg_log10.max())\n",
    "print(\"Min burden:\", 10**df.burden_peremp_avg_log10.min(), ' Max burden:', 10**df.burden_peremp_avg_log10.max())\n",
    "print('Min z-score:', df.ECF_std_dev.min(), 'Max z-score:', df.ECF_std_dev.max(),)\n",
    "for i in np.arange(-2,4,1):\n",
    "    ECF_log10_i, burden_log10_i = ECF_mean + ECF_std_dev * i, burden_mean + burden_std_dev * i\n",
    "    ECF_i, burden_i = 10**(ECF_log10_i), 10**(burden_log10_i)\n",
    "    print('Z-score:', i, ' ECF:', ECF_i, ' Burden:', burden_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed22652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_scope3.copy()\n",
    "ECF_std_dev, burden_std_dev = np.std(df.tonneCO2e_eff_peremp_avg_log10), np.std(df.burden_peremp_avg_log10)\n",
    "ECF_mean, burden_mean = df.tonneCO2e_eff_peremp_avg_log10.mean(), df.burden_peremp_avg_log10.mean()\n",
    "print(\"Logarithmic mean:\", ECF_mean, \" Std dev:\", ECF_std_dev, ' ECF at log mean:', 10**ECF_mean, ' Burden at log mean:', 10**burden_mean)\n",
    "print(\"Min Z-score:\", df.ECF_std_dev.min(), ' Max Z-score:', df.ECF_std_dev.max())\n",
    "print(\"Min ECF:\", 10**df.tonneCO2e_eff_peremp_avg_log10.min(), ' Max ECF:', 10**df.tonneCO2e_eff_peremp_avg_log10.max())\n",
    "print(\"Min burden:\", 10**df.burden_peremp_avg_log10.min(), ' Max burden:', 10**df.burden_peremp_avg_log10.max())\n",
    "print('Min z-score:', df.ECF_std_dev.min(), 'Max z-score:', df.ECF_std_dev.max(),)\n",
    "for i in np.arange(-2.4,3,0.8):\n",
    "    ECF_log10_i, burden_log10_i = ECF_mean + ECF_std_dev * i, burden_mean + burden_std_dev * i\n",
    "    ECF_i, burden_i = 10**(ECF_log10_i), 10**(burden_log10_i)\n",
    "    print('Z-score:', i, ' ECF:', ECF_i, ' Burden:', burden_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f47a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_sector_dfs['og'].copy()\n",
    "ECF_std_dev, burden_std_dev = np.std(df.tonneCO2e_eff_peremp_avg_log10), np.std(df.burden_peremp_avg_log10)\n",
    "ECF_mean, burden_mean = df.tonneCO2e_eff_peremp_avg_log10.mean(), df.burden_peremp_avg_log10.mean()\n",
    "\n",
    "print(\"Logarithmic mean:\", ECF_mean, \" Std dev:\", ECF_std_dev, ' ECF at log mean:', 10**ECF_mean, ' Burden at log mean:', 10**burden_mean)\n",
    "print(\"Min Z-score:\", df.ECF_std_dev.min(), ' Max Z-score:', df.ECF_std_dev.max())\n",
    "print(\"Min ECF:\", 10**df.tonneCO2e_eff_peremp_avg_log10.min(), ' Max ECF:', 10**df.tonneCO2e_eff_peremp_avg_log10.max())\n",
    "print(\"Min burden:\", 10**df.burden_peremp_avg_log10.min(), ' Max burden:', 10**df.burden_peremp_avg_log10.max())\n",
    "print('Min z-score:', df.ECF_std_dev.min(), 'Max z-score:', df.ECF_std_dev.max(),)\n",
    "for i in np.arange(-3,4,1):\n",
    "    ECF_log10_i, burden_log10_i = ECF_mean + ECF_std_dev * i, burden_mean + burden_std_dev * i\n",
    "    ECF_i, burden_i = 10**(ECF_log10_i), 10**(burden_log10_i)\n",
    "    print('Z-score:', i, ' ECF:', ECF_i, ' Burden:', burden_i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "6acd637b21fd7ea29bb5845175efb5db13b80787850369d781126c86d6bc808a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
